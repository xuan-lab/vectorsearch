#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬åˆ†ç±»æ•™è‚²åº”ç”¨
Text Classification Educational Application

è¿™ä¸ªåº”ç”¨å±•ç¤ºäº†æ–‡æœ¬åˆ†ç±»çš„å„ç§æŠ€æœ¯ï¼š
- æœ´ç´ è´å¶æ–¯åˆ†ç±»
- æ”¯æŒå‘é‡æœºåˆ†ç±»
- æ·±åº¦å­¦ä¹ åˆ†ç±»
- ç‰¹å¾å·¥ç¨‹
- æ¨¡å‹è¯„ä¼°å’Œæ¯”è¾ƒ

This application demonstrates various text classification techniques:
- Naive Bayes classification
- Support Vector Machine classification
- Deep learning classification
- Feature engineering
- Model evaluation and comparison
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import re
import time
from collections import defaultdict, Counter
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from src.text_vectorizer import TextVectorizer
from src.utils import load_documents

# å°è¯•å¯¼å…¥æœºå™¨å­¦ä¹ åº“
try:
    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.svm import SVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
    from sklearn.pipeline import Pipeline
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("æç¤º: å®‰è£…scikit-learnåº“ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ åŠŸèƒ½: pip install scikit-learn")

# å°è¯•å¯¼å…¥æ·±åº¦å­¦ä¹ åº“
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False
    print("æç¤º: å®‰è£…transformersåº“ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ åˆ†ç±»: pip install transformers")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class ClassificationResult:
    """åˆ†ç±»ç»“æœ"""
    text: str
    predicted_class: str
    confidence: float
    probabilities: Dict[str, float]
    method: str
    features_used: Optional[List[str]] = None

class NaiveBayesClassifier:
    """æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨"""
    
    def __init__(self, vectorizer_type: str = 'tfidf'):
        if not HAS_SKLEARN:
            raise ImportError("éœ€è¦å®‰è£…scikit-learnåº“")
        
        self.vectorizer_type = vectorizer_type
        if vectorizer_type == 'tfidf':
            self.vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))
        else:
            self.vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2))
        
        self.classifier = MultinomialNB()
        self.is_trained = False
        self.classes_ = None
    
    def train(self, texts: List[str], labels: List[str]):
        """è®­ç»ƒæ¨¡å‹"""
        X = self.vectorizer.fit_transform(texts)
        self.classifier.fit(X, labels)
        self.classes_ = self.classifier.classes_
        self.is_trained = True
        print(f"æœ´ç´ è´å¶æ–¯æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨ {len(texts)} ä¸ªæ ·æœ¬")
    
    def predict(self, text: str) -> ClassificationResult:
        """é¢„æµ‹æ–‡æœ¬ç±»åˆ«"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        X = self.vectorizer.transform([text])
        predicted_class = self.classifier.predict(X)[0]
        probabilities = self.classifier.predict_proba(X)[0]
        
        # è·å–ç‰¹å¾è¯
        feature_names = self.vectorizer.get_feature_names_out()
        feature_scores = X.toarray()[0]
        top_features = []
        if len(feature_scores) > 0:
            top_indices = np.argsort(feature_scores)[-10:]
            top_features = [feature_names[i] for i in top_indices if feature_scores[i] > 0]
        
        prob_dict = {cls: prob for cls, prob in zip(self.classes_, probabilities)}
        confidence = max(probabilities)
        
        return ClassificationResult(
            text=text,
            predicted_class=predicted_class,
            confidence=confidence,
            probabilities=prob_dict,
            method=f'naive_bayes_{self.vectorizer_type}',
            features_used=top_features
        )

class SVMClassifier:
    """æ”¯æŒå‘é‡æœºåˆ†ç±»å™¨"""
    
    def __init__(self, kernel: str = 'linear'):
        if not HAS_SKLEARN:
            raise ImportError("éœ€è¦å®‰è£…scikit-learnåº“")
        
        self.vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        self.classifier = SVC(kernel=kernel, probability=True, random_state=42)
        self.kernel = kernel
        self.is_trained = False
        self.classes_ = None
    
    def train(self, texts: List[str], labels: List[str]):
        """è®­ç»ƒæ¨¡å‹"""
        X = self.vectorizer.fit_transform(texts)
        self.classifier.fit(X, labels)
        self.classes_ = self.classifier.classes_
        self.is_trained = True
        print(f"SVMæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨ {len(texts)} ä¸ªæ ·æœ¬ï¼Œæ ¸å‡½æ•°: {self.kernel}")
    
    def predict(self, text: str) -> ClassificationResult:
        """é¢„æµ‹æ–‡æœ¬ç±»åˆ«"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        X = self.vectorizer.transform([text])
        predicted_class = self.classifier.predict(X)[0]
        probabilities = self.classifier.predict_proba(X)[0]
        
        prob_dict = {cls: prob for cls, prob in zip(self.classes_, probabilities)}
        confidence = max(probabilities)
        
        return ClassificationResult(
            text=text,
            predicted_class=predicted_class,
            confidence=confidence,
            probabilities=prob_dict,
            method=f'svm_{self.kernel}'
        )

class TransformerClassifier:
    """åŸºäºTransformerçš„åˆ†ç±»å™¨"""
    
    def __init__(self, model_name: str = "distilbert-base-uncased"):
        if not HAS_TRANSFORMERS:
            raise ImportError("éœ€è¦å®‰è£…transformersåº“")
        
        try:
            self.classifier = pipeline(
                "text-classification",
                model=model_name,
                return_all_scores=True
            )
            self.model_name = model_name
        except Exception as e:
            print(f"æ— æ³•åŠ è½½æ¨¡å‹ {model_name}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
            self.classifier = pipeline(
                "text-classification",
                return_all_scores=True
            )
            self.model_name = "default"
    
    def predict(self, text: str) -> ClassificationResult:
        """é¢„æµ‹æ–‡æœ¬ç±»åˆ«"""
        results = self.classifier(text)
        
        if isinstance(results[0], list):
            results = results[0]
        
        # æ‰¾åˆ°æœ€é«˜åˆ†æ•°çš„æ ‡ç­¾
        best_result = max(results, key=lambda x: x['score'])
        
        # åˆ›å»ºæ¦‚ç‡å­—å…¸
        prob_dict = {result['label']: result['score'] for result in results}
        
        return ClassificationResult(
            text=text,
            predicted_class=best_result['label'],
            confidence=best_result['score'],
            probabilities=prob_dict,
            method=f'transformer_{self.model_name}'
        )

class DatasetGenerator:
    """æ•°æ®é›†ç”Ÿæˆå™¨"""
    
    @staticmethod
    def create_sample_dataset() -> Tuple[List[str], List[str]]:
        """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†"""
        # ç§‘æŠ€ç±»æ–‡æœ¬
        tech_texts = [
            "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œä»æ™ºèƒ½æ‰‹æœºåˆ°è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€‚",
            "æ·±åº¦å­¦ä¹ ç®—æ³•åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
            "äº‘è®¡ç®—æŠ€æœ¯ä¸ºä¼ä¸šæä¾›äº†æ›´çµæ´»çš„ITè§£å†³æ–¹æ¡ˆã€‚",
            "åŒºå—é“¾æŠ€æœ¯æœ‰æœ›é©å‘½æ€§åœ°æ”¹å˜é‡‘èè¡Œä¸šã€‚",
            "æœºå™¨å­¦ä¹ æ¨¡å‹å¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å‡†ç¡®åœ°è¯Šæ–­ç–¾ç—…ã€‚",
            "ç‰©è”ç½‘è®¾å¤‡æ­£åœ¨è¿æ¥æˆ‘ä»¬å‘¨å›´çš„ä¸€åˆ‡ã€‚",
            "é‡å­è®¡ç®—å¯èƒ½åœ¨æœªæ¥å‡ åå¹´å†…æ”¹å˜è®¡ç®—èŒƒå¼ã€‚",
            "æ•°æ®ç§‘å­¦å®¶ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ä»å¤§æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚"
        ]
        
        # ä½“è‚²ç±»æ–‡æœ¬
        sports_texts = [
            "ä¸–ç•Œæ¯è¶³çƒèµ›æ˜¯å…¨çƒæœ€å—å…³æ³¨çš„ä½“è‚²èµ›äº‹ä¹‹ä¸€ã€‚",
            "ç¯®çƒè¿åŠ¨å‘˜éœ€è¦å‡ºè‰²çš„èº«ä½“ç´ è´¨å’Œå›¢é˜Ÿåˆä½œç²¾ç¥ã€‚",
            "å¥¥è¿ä¼šæ±‡èšäº†ä¸–ç•Œå„å›½æœ€ä¼˜ç§€çš„è¿åŠ¨å‘˜ã€‚",
            "ç½‘çƒæ¯”èµ›éœ€è¦å¼ºå¤§çš„å¿ƒç†ç´ è´¨å’Œç²¾æ¹›çš„æŠ€æœ¯ã€‚",
            "é©¬æ‹‰æ¾è·‘æ­¥è€ƒéªŒè¿åŠ¨å‘˜çš„è€åŠ›å’Œæ„å¿—åŠ›ã€‚",
            "æ¸¸æ³³æ˜¯ä¸€é¡¹å…¨èº«æ€§çš„æœ‰æ°§è¿åŠ¨ã€‚",
            "ç¾½æ¯›çƒè¿åŠ¨åœ¨äºšæ´²å›½å®¶éå¸¸å—æ¬¢è¿ã€‚",
            "å¥èº«æˆ¿è®­ç»ƒå¯ä»¥å¸®åŠ©äººä»¬ä¿æŒè‰¯å¥½çš„èº«ä½“çŠ¶æ€ã€‚"
        ]
        
        # å¨±ä¹ç±»æ–‡æœ¬
        entertainment_texts = [
            "ç”µå½±é™¢é‡Œæ’­æ”¾ç€æœ€æ–°çš„å¥½è±åå¤§ç‰‡ã€‚",
            "éŸ³ä¹ä¼šç°åœºè§‚ä¼—ä»¬çƒ­æƒ…é«˜æ¶¨åœ°ä¸ºæ­Œæ‰‹å–å½©ã€‚",
            "ç”µè§†å‰§çš„å‰§æƒ…è·Œå®•èµ·ä¼ï¼Œå¸å¼•äº†å¤§é‡è§‚ä¼—ã€‚",
            "æ¸¸æˆå¼€å‘å•†æ¨å‡ºäº†å…¨æ–°çš„è™šæ‹Ÿç°å®æ¸¸æˆã€‚",
            "æ˜æ˜Ÿä»¬åœ¨çº¢æ¯¯ä¸Šå±•ç¤ºæœ€æ–°çš„æ—¶å°šé€ å‹ã€‚",
            "åŠ¨æ¼«ä½œå“æ·±å—å¹´è½»äººçš„å–œçˆ±ã€‚",
            "ç»¼è‰ºèŠ‚ç›®ä¸ºè§‚ä¼—å¸¦æ¥äº†æ¬¢å£°ç¬‘è¯­ã€‚",
            "è¯»ä¹¦æ˜¯ä¸€ç§å¾ˆå¥½çš„å¨±ä¹å’Œå­¦ä¹ æ–¹å¼ã€‚"
        ]
        
        # åˆå¹¶æ•°æ®
        texts = tech_texts + sports_texts + entertainment_texts
        labels = ['ç§‘æŠ€'] * len(tech_texts) + ['ä½“è‚²'] * len(sports_texts) + ['å¨±ä¹'] * len(entertainment_texts)
        
        return texts, labels

class TextClassificationApp:
    """æ–‡æœ¬åˆ†ç±»æ•™è‚²åº”ç”¨"""
    
    def __init__(self):
        self.classifiers = {}
        self.training_data = None
        self.test_data = None
        self.results_history = []
        
        # åˆå§‹åŒ–åˆ†ç±»å™¨
        if HAS_SKLEARN:
            self.classifiers['naive_bayes_tfidf'] = NaiveBayesClassifier('tfidf')
            self.classifiers['naive_bayes_count'] = NaiveBayesClassifier('count')
            self.classifiers['svm_linear'] = SVMClassifier('linear')
            self.classifiers['svm_rbf'] = SVMClassifier('rbf')
        
        if HAS_TRANSFORMERS:
            try:
                self.classifiers['transformer'] = TransformerClassifier()
            except Exception as e:
                print(f"æ— æ³•åˆå§‹åŒ–Transformeråˆ†ç±»å™¨: {e}")
    
    def load_dataset(self, texts: List[str] = None, labels: List[str] = None):
        """åŠ è½½æ•°æ®é›†"""
        if texts is None or labels is None:
            texts, labels = DatasetGenerator.create_sample_dataset()
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        if HAS_SKLEARN:
            train_texts, test_texts, train_labels, test_labels = train_test_split(
                texts, labels, test_size=0.2, random_state=42, stratify=labels
            )
            self.training_data = (train_texts, train_labels)
            self.test_data = (test_texts, test_labels)
        else:
            # ç®€å•åˆ†å‰²
            split_idx = int(len(texts) * 0.8)
            self.training_data = (texts[:split_idx], labels[:split_idx])
            self.test_data = (texts[split_idx:], labels[split_idx:])
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"è®­ç»ƒé›†: {len(self.training_data[0])} ä¸ªæ ·æœ¬")
        print(f"æµ‹è¯•é›†: {len(self.test_data[0])} ä¸ªæ ·æœ¬")
        print(f"ç±»åˆ«: {set(labels)}")
    
    def train_all_classifiers(self):
        """è®­ç»ƒæ‰€æœ‰åˆ†ç±»å™¨"""
        if self.training_data is None:
            self.load_dataset()
        
        train_texts, train_labels = self.training_data
        
        for name, classifier in self.classifiers.items():
            if name != 'transformer':  # Transformerä¸éœ€è¦è®­ç»ƒ
                try:
                    print(f"\næ­£åœ¨è®­ç»ƒ {name}...")
                    classifier.train(train_texts, train_labels)
                except Exception as e:
                    print(f"è®­ç»ƒ {name} å¤±è´¥: {e}")
    
    def classify_text(self, text: str, methods: List[str] = None) -> Dict[str, ClassificationResult]:
        """åˆ†ç±»å•ä¸ªæ–‡æœ¬"""
        if methods is None:
            methods = list(self.classifiers.keys())
        
        results = {}
        for method in methods:
            if method in self.classifiers:
                try:
                    if method == 'transformer':
                        result = self.classifiers[method].predict(text)
                    else:
                        if hasattr(self.classifiers[method], 'is_trained') and not self.classifiers[method].is_trained:
                            print(f"æ¨¡å‹ {method} å°šæœªè®­ç»ƒ")
                            continue
                        result = self.classifiers[method].predict(text)
                    results[method] = result
                except Exception as e:
                    print(f"æ–¹æ³• {method} åˆ†ç±»å¤±è´¥: {e}")
        
        return results
    
    def compare_methods(self, text: str):
        """æ¯”è¾ƒä¸åŒæ–¹æ³•çš„åˆ†ç±»ç»“æœ"""
        results = self.classify_text(text)
        
        print(f"\næ–‡æœ¬: {text}")
        print("=" * 80)
        
        for method, result in results.items():
            print(f"\n{method.upper()}:")
            print(f"  é¢„æµ‹ç±»åˆ«: {result.predicted_class}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
            print(f"  æ¦‚ç‡åˆ†å¸ƒ:")
            for cls, prob in result.probabilities.items():
                print(f"    {cls}: {prob:.3f}")
            
            if result.features_used:
                print(f"  å…³é”®ç‰¹å¾: {', '.join(result.features_used[:5])}")
    
    def evaluate_performance(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if self.test_data is None:
            print("æ²¡æœ‰æµ‹è¯•æ•°æ®")
            return
        
        test_texts, test_labels = self.test_data
        
        print("\næ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        print("=" * 60)
        
        for name, classifier in self.classifiers.items():
            if name == 'transformer':
                continue  # è·³è¿‡Transformerè¯„ä¼°
            
            if not hasattr(classifier, 'is_trained') or not classifier.is_trained:
                continue
            
            try:
                predictions = []
                confidences = []
                
                for text in test_texts:
                    result = classifier.predict(text)
                    predictions.append(result.predicted_class)
                    confidences.append(result.confidence)
                
                if HAS_SKLEARN:
                    accuracy = accuracy_score(test_labels, predictions)
                    print(f"\n{name.upper()}:")
                    print(f"  å‡†ç¡®ç‡: {accuracy:.3f}")
                    print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.3f}")
                    
                    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
                    print("  åˆ†ç±»æŠ¥å‘Š:")
                    report = classification_report(test_labels, predictions)
                    for line in report.split('\n')[2:-3]:  # è·³è¿‡å¤´éƒ¨å’Œå°¾éƒ¨
                        if line.strip():
                            print(f"    {line}")
                
            except Exception as e:
                print(f"è¯„ä¼° {name} å¤±è´¥: {e}")
    
    def visualize_classification_results(self, texts: List[str]):
        """å¯è§†åŒ–åˆ†ç±»ç»“æœ"""
        if not self.classifiers:
            print("æ²¡æœ‰å¯ç”¨çš„åˆ†ç±»å™¨")
            return
        
        # æ”¶é›†æ‰€æœ‰ç»“æœ
        all_results = []
        for text in texts:
            results = self.classify_text(text)
            for method, result in results.items():
                if method != 'transformer':  # æ’é™¤transformerç»“æœ
                    all_results.append({
                        'text': text[:30] + '...' if len(text) > 30 else text,
                        'method': method,
                        'predicted_class': result.predicted_class,
                        'confidence': result.confidence
                    })
        
        if not all_results:
            print("æ²¡æœ‰åˆ†ç±»ç»“æœå¯è§†åŒ–")
            return
        
        df = pd.DataFrame(all_results)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. æ–¹æ³•å‡†ç¡®åº¦æ¯”è¾ƒ
        if 'method' in df.columns:
            method_confidence = df.groupby('method')['confidence'].mean()
            axes[0, 0].bar(range(len(method_confidence)), method_confidence.values)
            axes[0, 0].set_xticks(range(len(method_confidence)))
            axes[0, 0].set_xticklabels(method_confidence.index, rotation=45)
            axes[0, 0].set_title('å„æ–¹æ³•å¹³å‡ç½®ä¿¡åº¦')
            axes[0, 0].set_ylabel('å¹³å‡ç½®ä¿¡åº¦')
        
        # 2. ç±»åˆ«åˆ†å¸ƒ
        if 'predicted_class' in df.columns:
            class_counts = df['predicted_class'].value_counts()
            axes[0, 1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')
            axes[0, 1].set_title('é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ')
        
        # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
        if 'confidence' in df.columns:
            axes[1, 0].hist(df['confidence'], bins=20, alpha=0.7, edgecolor='black')
            axes[1, 0].set_xlabel('ç½®ä¿¡åº¦')
            axes[1, 0].set_ylabel('é¢‘æ¬¡')
            axes[1, 0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
        
        # 4. æ–¹æ³•vsç±»åˆ«çƒ­åŠ›å›¾
        if 'method' in df.columns and 'predicted_class' in df.columns:
            pivot_table = df.pivot_table(
                values='confidence', 
                index='method', 
                columns='predicted_class', 
                aggfunc='mean'
            )
            sns.heatmap(pivot_table, annot=True, fmt='.3f', ax=axes[1, 1])
            axes[1, 1].set_title('æ–¹æ³•-ç±»åˆ«ç½®ä¿¡åº¦çƒ­åŠ›å›¾')
        
        plt.tight_layout()
        plt.show()
    
    def feature_importance_analysis(self, method: str = 'naive_bayes_tfidf'):
        """ç‰¹å¾é‡è¦æ€§åˆ†æ"""
        if method not in self.classifiers or method == 'transformer':
            print(f"æ–¹æ³• {method} ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
            return
        
        classifier = self.classifiers[method]
        if not hasattr(classifier, 'is_trained') or not classifier.is_trained:
            print(f"æ¨¡å‹ {method} å°šæœªè®­ç»ƒ")
            return
        
        try:
            # è·å–ç‰¹å¾åç§°
            feature_names = classifier.vectorizer.get_feature_names_out()
            
            if hasattr(classifier.classifier, 'feature_log_prob_'):
                # æœ´ç´ è´å¶æ–¯ç‰¹å¾é‡è¦æ€§
                classes = classifier.classifier.classes_
                
                plt.figure(figsize=(15, 8))
                for i, cls in enumerate(classes):
                    feature_importance = classifier.classifier.feature_log_prob_[i]
                    top_indices = np.argsort(feature_importance)[-10:]
                    top_features = [feature_names[idx] for idx in top_indices]
                    top_scores = feature_importance[top_indices]
                    
                    plt.subplot(1, len(classes), i+1)
                    plt.barh(range(len(top_features)), top_scores)
                    plt.yticks(range(len(top_features)), top_features)
                    plt.title(f'ç±»åˆ«: {cls}')
                    plt.xlabel('ç‰¹å¾é‡è¦æ€§')
                
                plt.tight_layout()
                plt.show()
            
            elif hasattr(classifier.classifier, 'coef_'):
                # SVMç‰¹å¾é‡è¦æ€§
                feature_importance = np.abs(classifier.classifier.coef_[0])
                top_indices = np.argsort(feature_importance)[-20:]
                top_features = [feature_names[idx] for idx in top_indices]
                top_scores = feature_importance[top_indices]
                
                plt.figure(figsize=(12, 8))
                plt.barh(range(len(top_features)), top_scores)
                plt.yticks(range(len(top_features)), top_features)
                plt.title(f'{method} ç‰¹å¾é‡è¦æ€§')
                plt.xlabel('é‡è¦æ€§åˆ†æ•°')
                plt.show()
        
        except Exception as e:
            print(f"ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
    
    def run_interactive_demo(self):
        """è¿è¡Œäº¤äº’å¼æ¼”ç¤º"""
        print("\nğŸ“Š æ–‡æœ¬åˆ†ç±»æ•™è‚²åº”ç”¨")
        print("=" * 50)
        print("å¯ç”¨çš„åˆ†ç±»æ–¹æ³•:")
        for i, method in enumerate(self.classifiers.keys(), 1):
            print(f"  {i}. {method}")
        
        while True:
            print("\né€‰æ‹©æ“ä½œ:")
            print("1. è®­ç»ƒæ¨¡å‹")
            print("2. å•æ–‡æœ¬åˆ†ç±»")
            print("3. æ–¹æ³•æ¯”è¾ƒ")
            print("4. æ€§èƒ½è¯„ä¼°")
            print("5. æ‰¹é‡åˆ†ç±»å¯è§†åŒ–")
            print("6. ç‰¹å¾é‡è¦æ€§åˆ†æ")
            print("7. åŠ è½½è‡ªå®šä¹‰æ•°æ®é›†")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹© (0-7): ").strip()
            
            if choice == '0':
                break
            
            elif choice == '1':
                self.train_all_classifiers()
            
            elif choice == '2':
                text = input("è¯·è¾“å…¥è¦åˆ†ç±»çš„æ–‡æœ¬: ").strip()
                if text:
                    method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join(self.classifiers.keys())}): ").strip()
                    if method in self.classifiers:
                        try:
                            result = self.classify_text(text, [method])[method]
                            print(f"\né¢„æµ‹ç±»åˆ«: {result.predicted_class}")
                            print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
                            print("æ¦‚ç‡åˆ†å¸ƒ:")
                            for cls, prob in result.probabilities.items():
                                print(f"  {cls}: {prob:.3f}")
                        except Exception as e:
                            print(f"åˆ†ç±»å¤±è´¥: {e}")
                    else:
                        print("æ— æ•ˆçš„æ–¹æ³•")
            
            elif choice == '3':
                text = input("è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
                if text:
                    self.compare_methods(text)
            
            elif choice == '4':
                self.evaluate_performance()
            
            elif choice == '5':
                print("è¯·è¾“å…¥å¤šä¸ªæ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ª (è¾“å…¥ç©ºè¡Œç»“æŸ):")
                texts = []
                while True:
                    line = input().strip()
                    if not line:
                        break
                    texts.append(line)
                
                if texts:
                    self.visualize_classification_results(texts)
            
            elif choice == '6':
                method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join([m for m in self.classifiers.keys() if m != 'transformer'])}): ").strip()
                if method in self.classifiers and method != 'transformer':
                    self.feature_importance_analysis(method)
                else:
                    print("æ— æ•ˆçš„æ–¹æ³•æˆ–æ–¹æ³•ä¸æ”¯æŒç‰¹å¾åˆ†æ")
            
            elif choice == '7':
                try:
                    file_path = input("è¯·è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼): ").strip()
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        if isinstance(data, list) and len(data) > 0:
                            if 'text' in data[0] and 'label' in data[0]:
                                texts = [item['text'] for item in data]
                                labels = [item['label'] for item in data]
                                self.load_dataset(texts, labels)
                            else:
                                print("æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å« 'text' å’Œ 'label' å­—æ®µ")
                        else:
                            print("æ•°æ®æ ¼å¼é”™è¯¯")
                    else:
                        print("æ–‡ä»¶ä¸å­˜åœ¨")
                except Exception as e:
                    print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("åˆå§‹åŒ–æ–‡æœ¬åˆ†ç±»åº”ç”¨...")
    
    app = TextClassificationApp()
    
    # åŠ è½½ç¤ºä¾‹æ•°æ®é›†
    app.load_dataset()
    
    # è®­ç»ƒæ¨¡å‹
    print("\nè®­ç»ƒåˆ†ç±»æ¨¡å‹...")
    app.train_all_classifiers()
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_texts = [
        "æœ€æ–°çš„äººå·¥æ™ºèƒ½æŠ€æœ¯å°†æ”¹å˜åŒ»ç–—è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚",
        "è¶³çƒä¸–ç•Œæ¯å†³èµ›å¸å¼•äº†å…¨çƒæ•°äº¿è§‚ä¼—è§‚çœ‹ã€‚",
        "è¿™éƒ¨ç”µå½±çš„ç‰¹æ•ˆåˆ¶ä½œéå¸¸ç²¾å½©ï¼Œæ•…äº‹æƒ…èŠ‚å¼•äººå…¥èƒœã€‚"
    ]
    
    print("\nğŸ¯ æ¼”ç¤º: å¤šæ–¹æ³•æ–‡æœ¬åˆ†ç±»")
    print("=" * 40)
    
    # æ¯”è¾ƒä¸åŒåˆ†ç±»æ–¹æ³•
    for text in sample_texts:
        app.compare_methods(text)
        print()
    
    # æ€§èƒ½è¯„ä¼°
    print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°")
    app.evaluate_performance()
    
    # å¯è§†åŒ–åˆ†æ
    if sample_texts:
        print("\nğŸ“ˆ å¯è§†åŒ–åˆ†æ")
        app.visualize_classification_results(sample_texts)
    
    # è¿è¡Œäº¤äº’å¼æ¼”ç¤º
    app.run_interactive_demo()

if __name__ == "__main__":
    main()

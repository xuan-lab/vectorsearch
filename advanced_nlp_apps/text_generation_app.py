#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬ç”Ÿæˆæ•™è‚²åº”ç”¨
Text Generation Educational Application

è¿™ä¸ªåº”ç”¨å±•ç¤ºäº†æ–‡æœ¬ç”Ÿæˆçš„å„ç§æŠ€æœ¯ï¼š
- N-gramè¯­è¨€æ¨¡å‹
- é©¬å°”å¯å¤«é“¾æ–‡æœ¬ç”Ÿæˆ
- åŸºäºæ¨¡æ¿çš„æ–‡æœ¬ç”Ÿæˆ
- Transformeræ–‡æœ¬ç”Ÿæˆ
- æ–‡æœ¬é£æ ¼è¿ç§»
- åˆ›æ„å†™ä½œè¾…åŠ©

This application demonstrates various text generation techniques:
- N-gram language models
- Markov chain text generation
- Template-based text generation
- Transformer text generation
- Text style transfer
- Creative writing assistance
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional, Any, Set
from dataclasses import dataclass
import re
import time
import random
from collections import defaultdict, Counter, deque
import json
import pickle

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from src.text_vectorizer import TextVectorizer
from src.utils import load_documents

# å°è¯•å¯¼å…¥æ·±åº¦å­¦ä¹ åº“
try:
    from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, AutoModelForCausalLM
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False
    print("æç¤º: å®‰è£…transformersåº“ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–‡æœ¬ç”Ÿæˆ: pip install transformers")

# å°è¯•å¯¼å…¥NLTK
try:
    import nltk
    from nltk.util import ngrams
    from nltk.tokenize import sent_tokenize, word_tokenize
    HAS_NLTK = True
except ImportError:
    HAS_NLTK = False
    print("æç¤º: å®‰è£…NLTKåº“ä»¥è·å¾—æ›´å¥½çš„æ–‡æœ¬å¤„ç†: pip install nltk")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class GenerationResult:
    """æ–‡æœ¬ç”Ÿæˆç»“æœ"""
    generated_text: str
    method: str
    confidence: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class NGramLanguageModel:
    """N-gramè¯­è¨€æ¨¡å‹"""
    
    def __init__(self, n: int = 3):
        self.n = n
        self.ngrams = defaultdict(Counter)
        self.vocabulary = set()
        self.is_trained = False
    
    def train(self, texts: List[str]):
        """è®­ç»ƒN-gramæ¨¡å‹"""
        print(f"è®­ç»ƒ {self.n}-gram è¯­è¨€æ¨¡å‹...")
        
        all_tokens = []
        for text in texts:
            # ç®€å•åˆ†è¯
            tokens = self._tokenize(text)
            all_tokens.extend(tokens)
            self.vocabulary.update(tokens)
        
        # ç”Ÿæˆn-grams
        for i in range(len(all_tokens) - self.n + 1):
            prefix = tuple(all_tokens[i:i+self.n-1])
            next_word = all_tokens[i+self.n-1]
            self.ngrams[prefix][next_word] += 1
        
        self.is_trained = True
        print(f"è®­ç»ƒå®Œæˆï¼Œè¯æ±‡é‡: {len(self.vocabulary)}, N-gramæ•°é‡: {len(self.ngrams)}")
    
    def _tokenize(self, text: str) -> List[str]:
        """ç®€å•åˆ†è¯"""
        # æ·»åŠ å¥å­å¼€å§‹å’Œç»“æŸæ ‡è®°
        tokens = ['<START>'] * (self.n - 1)
        
        # ä¸­è‹±æ–‡æ··åˆåˆ†è¯
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
        words = re.findall(r'\w+', text)
        tokens.extend(words)
        tokens.append('<END>')
        
        return tokens
    
    def generate_text(self, prompt: str = "", max_length: int = 100) -> GenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self.is_trained:
            return GenerationResult("", "ngram", 0.0, {"error": "æ¨¡å‹æœªè®­ç»ƒ"})
        
        if prompt:
            tokens = self._tokenize(prompt)[-self.n+1:]  # è·å–æœ€ån-1ä¸ªè¯ä½œä¸ºå¼€å§‹
        else:
            # éšæœºé€‰æ‹©ä¸€ä¸ªå¼€å§‹
            tokens = list(random.choice(list(self.ngrams.keys())))
        
        generated_tokens = tokens[:]
        
        for _ in range(max_length):
            prefix = tuple(generated_tokens[-(self.n-1):])
            
            if prefix not in self.ngrams:
                break
            
            # æ ¹æ®æ¦‚ç‡é€‰æ‹©ä¸‹ä¸€ä¸ªè¯
            next_words = self.ngrams[prefix]
            if not next_words:
                break
            
            # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
            total_count = sum(next_words.values())
            probabilities = [count / total_count for count in next_words.values()]
            
            next_word = np.random.choice(list(next_words.keys()), p=probabilities)
            
            if next_word == '<END>':
                break
            
            generated_tokens.append(next_word)
        
        # ç§»é™¤ç‰¹æ®Šæ ‡è®°å¹¶é‡æ„æ–‡æœ¬
        filtered_tokens = [token for token in generated_tokens if token not in ['<START>', '<END>']]
        generated_text = ' '.join(filtered_tokens)
        
        # è®¡ç®—å¹³å‡æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
        confidence = self._calculate_confidence(generated_tokens)
        
        return GenerationResult(
            generated_text,
            "ngram",
            confidence,
            {"n": self.n, "tokens_generated": len(filtered_tokens)}
        )
    
    def _calculate_confidence(self, tokens: List[str]) -> float:
        """è®¡ç®—ç”Ÿæˆæ–‡æœ¬çš„ç½®ä¿¡åº¦"""
        if len(tokens) < self.n:
            return 0.0
        
        probabilities = []
        for i in range(self.n-1, len(tokens)):
            prefix = tuple(tokens[i-self.n+1:i])
            if prefix in self.ngrams and tokens[i] in self.ngrams[prefix]:
                total_count = sum(self.ngrams[prefix].values())
                prob = self.ngrams[prefix][tokens[i]] / total_count
                probabilities.append(prob)
        
        return np.mean(probabilities) if probabilities else 0.0

class MarkovChainGenerator:
    """é©¬å°”å¯å¤«é“¾æ–‡æœ¬ç”Ÿæˆå™¨"""
    
    def __init__(self, order: int = 2):
        self.order = order
        self.transitions = defaultdict(Counter)
        self.is_trained = False
    
    def train(self, texts: List[str]):
        """è®­ç»ƒé©¬å°”å¯å¤«é“¾"""
        print(f"è®­ç»ƒ {self.order} é˜¶é©¬å°”å¯å¤«é“¾...")
        
        for text in texts:
            sentences = self._split_sentences(text)
            for sentence in sentences:
                words = self._tokenize(sentence)
                if len(words) >= self.order + 1:
                    for i in range(len(words) - self.order):
                        state = tuple(words[i:i+self.order])
                        next_word = words[i+self.order]
                        self.transitions[state][next_word] += 1
        
        self.is_trained = True
        print(f"è®­ç»ƒå®Œæˆï¼ŒçŠ¶æ€æ•°é‡: {len(self.transitions)}")
    
    def _split_sentences(self, text: str) -> List[str]:
        """åˆ†å¥"""
        if HAS_NLTK:
            return sent_tokenize(text)
        else:
            return re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)
    
    def _tokenize(self, text: str) -> List[str]:
        """åˆ†è¯"""
        if HAS_NLTK:
            return word_tokenize(text.lower())
        else:
            return re.findall(r'\w+', text.lower())
    
    def generate_text(self, prompt: str = "", max_length: int = 100) -> GenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self.is_trained:
            return GenerationResult("", "markov", 0.0, {"error": "æ¨¡å‹æœªè®­ç»ƒ"})
        
        if prompt:
            words = self._tokenize(prompt)
            if len(words) >= self.order:
                current_state = tuple(words[-self.order:])
            else:
                current_state = random.choice(list(self.transitions.keys()))
        else:
            current_state = random.choice(list(self.transitions.keys()))
        
        result = list(current_state)
        
        for _ in range(max_length):
            if current_state not in self.transitions:
                break
            
            next_words = self.transitions[current_state]
            if not next_words:
                break
            
            # é€‰æ‹©ä¸‹ä¸€ä¸ªè¯
            total_count = sum(next_words.values())
            probabilities = [count / total_count for count in next_words.values()]
            next_word = np.random.choice(list(next_words.keys()), p=probabilities)
            
            result.append(next_word)
            current_state = tuple(result[-self.order:])
        
        generated_text = ' '.join(result)
        confidence = len(result) / max_length  # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—
        
        return GenerationResult(
            generated_text,
            "markov",
            confidence,
            {"order": self.order, "words_generated": len(result)}
        )

class TemplateGenerator:
    """åŸºäºæ¨¡æ¿çš„æ–‡æœ¬ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.templates = {}
        self.word_categories = defaultdict(list)
        self._initialize_templates()
    
    def _initialize_templates(self):
        """åˆå§‹åŒ–æ¨¡æ¿"""
        self.templates = {
            "product_review": [
                "è¿™ä¸ª{product}çœŸçš„å¾ˆ{adjective}ï¼Œæˆ‘{verb}å®ƒã€‚",
                "æˆ‘å¯¹è¿™ä¸ª{product}æ„Ÿåˆ°{emotion}ï¼Œå› ä¸ºå®ƒ{reason}ã€‚",
                "{product}çš„{feature}è®©äººå°è±¡æ·±åˆ»ï¼Œç‰¹åˆ«æ˜¯{detail}ã€‚"
            ],
            "news_headline": [
                "{location}å‘ç”Ÿ{event}ï¼Œ{result}ã€‚",
                "{person}å®£å¸ƒ{announcement}ï¼Œå¼•å‘{reaction}ã€‚",
                "{number}{unit}{item}åœ¨{place}{action}ã€‚"
            ],
            "story_beginning": [
                "åœ¨ä¸€ä¸ª{weather}çš„{time}ï¼Œ{character}èµ°è¿›äº†{place}ã€‚",
                "{character}ä»æ¥æ²¡æœ‰æƒ³è¿‡{event}ä¼šå‘ç”Ÿåœ¨{situation}ã€‚",
                "å½“{character}çœ‹åˆ°{object}æ—¶ï¼Œ{emotion}æ¶Œä¸Šå¿ƒå¤´ã€‚"
            ]
        }
        
        # è¯æ±‡åˆ†ç±»
        self.word_categories = {
            "product": ["æ‰‹æœº", "ç”µè„‘", "ä¹¦ç±", "ç”µå½±", "é¤å…", "æ±½è½¦"],
            "adjective": ["æ£’", "å·®", "è´µ", "ä¾¿å®œ", "å®ç”¨", "æ¼‚äº®"],
            "verb": ["å–œæ¬¢", "è®¨åŒ", "æ¨è", "è´­ä¹°", "ä½¿ç”¨", "è¯„ä»·"],
            "emotion": ["æ»¡æ„", "å¤±æœ›", "æƒŠå–œ", "æ„¤æ€’", "å¼€å¿ƒ", "æ‹…å¿ƒ"],
            "reason": ["è´¨é‡å¥½", "ä»·æ ¼åˆç†", "æœåŠ¡ä¼˜ç§€", "åŠŸèƒ½å¼ºå¤§", "è®¾è®¡ç²¾ç¾"],
            "feature": ["å¤–è§‚", "æ€§èƒ½", "ä»·æ ¼", "æœåŠ¡", "åŠŸèƒ½", "è´¨é‡"],
            "detail": ["é¢œè‰²æ­é…", "è¿è¡Œé€Ÿåº¦", "æ€§ä»·æ¯”", "ç”¨æˆ·ä½“éªŒ"],
            "location": ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "æˆéƒ½"],
            "event": ["ä¼šè®®", "å±•è§ˆ", "æ¯”èµ›", "äº‹æ•…", "åº†å…¸", "å‘å¸ƒä¼š"],
            "result": ["è·å¾—æˆåŠŸ", "å¼•èµ·å…³æ³¨", "é€ æˆå½±å“", "å¾—åˆ°å¥½è¯„"],
            "person": ["ä¸“å®¶", "å®˜å‘˜", "ä¼ä¸šå®¶", "ç§‘å­¦å®¶", "è‰ºæœ¯å®¶"],
            "announcement": ["æ–°æ”¿ç­–", "åˆä½œè®¡åˆ’", "ç ”ç©¶æˆæœ", "äº§å“å‘å¸ƒ"],
            "reaction": ["çƒ­çƒˆè®¨è®º", "å¹¿æ³›å…³æ³¨", "ç§¯æå“åº”", "ä¸åŒçœ‹æ³•"],
            "weather": ["æ™´æœ—", "é˜´æ²‰", "ä¸‹é›¨", "ä¸‹é›ª", "å¤šäº‘"],
            "time": ["æ—©æ™¨", "ä¸‹åˆ", "å‚æ™š", "æ·±å¤œ", "å‘¨æœ«"],
            "character": ["å°æ˜", "å¥³å­©", "è€äºº", "å­¦ç”Ÿ", "å•†äºº", "ä½œå®¶"],
            "place": ["å›¾ä¹¦é¦†", "å’–å•¡å…", "å…¬å›­", "å•†åº—", "å­¦æ ¡", "å®¶ä¸­"],
            "object": ["ä¿¡ä»¶", "ç…§ç‰‡", "é’¥åŒ™", "ä¹¦æœ¬", "æ‰‹æœº", "ç¤¼ç‰©"],
            "situation": ["è¿™ç§æƒ…å†µä¸‹", "é‚£ä¸ªæ—¶å€™", "å…³é”®æ—¶åˆ»", "æ„å¤–æƒ…å†µä¸‹"]
        }
    
    def add_template(self, category: str, template: str):
        """æ·»åŠ æ¨¡æ¿"""
        if category not in self.templates:
            self.templates[category] = []
        self.templates[category].append(template)
    
    def add_words(self, category: str, words: List[str]):
        """æ·»åŠ è¯æ±‡"""
        self.word_categories[category].extend(words)
    
    def generate_text(self, template_category: str, custom_values: Dict[str, str] = None) -> GenerationResult:
        """åŸºäºæ¨¡æ¿ç”Ÿæˆæ–‡æœ¬"""
        if template_category not in self.templates:
            return GenerationResult("", "template", 0.0, {"error": f"æœªæ‰¾åˆ°æ¨¡æ¿ç±»åˆ«: {template_category}"})
        
        template = random.choice(self.templates[template_category])
        
        # æŸ¥æ‰¾æ¨¡æ¿ä¸­çš„å ä½ç¬¦
        placeholders = re.findall(r'\{(\w+)\}', template)
        
        # å¡«å……å ä½ç¬¦
        filled_template = template
        used_words = {}
        
        for placeholder in placeholders:
            if custom_values and placeholder in custom_values:
                word = custom_values[placeholder]
            elif placeholder in self.word_categories:
                word = random.choice(self.word_categories[placeholder])
            else:
                word = f"[{placeholder}]"  # æœªæ‰¾åˆ°å¯¹åº”è¯æ±‡
            
            used_words[placeholder] = word
            filled_template = filled_template.replace(f"{{{placeholder}}}", word)
        
        confidence = 1.0 - (filled_template.count('[') / len(placeholders)) if placeholders else 1.0
        
        return GenerationResult(
            filled_template,
            "template",
            confidence,
            {
                "template_category": template_category,
                "used_words": used_words,
                "placeholders": placeholders
            }
        )

class TransformerGenerator:
    """åŸºäºTransformerçš„æ–‡æœ¬ç”Ÿæˆå™¨"""
    
    def __init__(self, model_name: str = "gpt2"):
        self.model_name = model_name
        self.generator = None
        self.is_available = False
        
        if HAS_TRANSFORMERS:
            try:
                print(f"åŠ è½½ {model_name} æ¨¡å‹...")
                self.generator = pipeline("text-generation", model=model_name)
                self.is_available = True
                print("æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def generate_text(self, prompt: str, max_length: int = 100, temperature: float = 0.7) -> GenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self.is_available:
            return GenerationResult("", "transformer", 0.0, {"error": "Transformeræ¨¡å‹ä¸å¯ç”¨"})
        
        try:
            results = self.generator(
                prompt,
                max_length=max_length,
                temperature=temperature,
                do_sample=True,
                num_return_sequences=1,
                pad_token_id=self.generator.tokenizer.eos_token_id
            )
            
            generated_text = results[0]['generated_text']
            
            # ç§»é™¤åŸå§‹prompt
            if generated_text.startswith(prompt):
                generated_text = generated_text[len(prompt):].strip()
            
            return GenerationResult(
                generated_text,
                "transformer",
                0.8,  # å›ºå®šç½®ä¿¡åº¦
                {
                    "model_name": self.model_name,
                    "temperature": temperature,
                    "max_length": max_length
                }
            )
        
        except Exception as e:
            return GenerationResult("", "transformer", 0.0, {"error": str(e)})

class TextStyleTransfer:
    """æ–‡æœ¬é£æ ¼è¿ç§»"""
    
    def __init__(self):
        self.style_rules = {
            "formal": {
                "replacements": {
                    "å¾ˆå¥½": "éå¸¸ä¼˜ç§€",
                    "ä¸é”™": "ä»¤äººæ»¡æ„",
                    "ç³Ÿç³•": "ä¸å°½å¦‚äººæ„",
                    "ä¾¿å®œ": "ä»·æ ¼åˆç†",
                    "è´µ": "ä»·æ ¼åé«˜"
                },
                "patterns": [
                    (r"æˆ‘è§‰å¾—", "æœ¬äººè®¤ä¸º"),
                    (r"åº”è¯¥", "ç†åº”"),
                    (r"å¯èƒ½", "æˆ–è®¸"),
                    (r"å¤§æ¦‚", "å¤§è‡´")
                ]
            },
            "casual": {
                "replacements": {
                    "éå¸¸ä¼˜ç§€": "è¶…æ£’",
                    "ä»¤äººæ»¡æ„": "è¿˜ä¸é”™",
                    "ä¸å°½å¦‚äººæ„": "æœ‰ç‚¹ç³Ÿ",
                    "ä»·æ ¼åˆç†": "ä¾¿å®œ",
                    "ä»·æ ¼åé«˜": "å¤ªè´µäº†"
                },
                "patterns": [
                    (r"æœ¬äººè®¤ä¸º", "æˆ‘è§‰å¾—"),
                    (r"ç†åº”", "åº”è¯¥"),
                    (r"æˆ–è®¸", "å¯èƒ½"),
                    (r"å¤§è‡´", "å¤§æ¦‚")
                ]
            },
            "poetic": {
                "replacements": {
                    "ç¾ä¸½": "ç»šçƒ‚",
                    "å¿«ä¹": "æ¬¢æ„‰",
                    "æ‚²ä¼¤": "æƒ†æ€…",
                    "æ€è€ƒ": "æ²‰æ€",
                    "çœ‹è§": "æœ›è§"
                },
                "patterns": [
                    (r"(\w+)å¾ˆ(\w+)", r"\1å¦‚æ­¤\2"),
                    (r"åœ¨(\w+)", r"äº\1ä¹‹ä¸­"),
                    (r"èµ°è·¯", "è¸±æ­¥"),
                    (r"è¯´è¯", "è¨€è¯­")
                ]
            }
        }
    
    def transfer_style(self, text: str, target_style: str) -> GenerationResult:
        """é£æ ¼è¿ç§»"""
        if target_style not in self.style_rules:
            return GenerationResult("", "style_transfer", 0.0, {"error": f"ä¸æ”¯æŒçš„é£æ ¼: {target_style}"})
        
        rules = self.style_rules[target_style]
        result_text = text
        changes_made = 0
        
        # åº”ç”¨è¯æ±‡æ›¿æ¢
        for old_word, new_word in rules["replacements"].items():
            if old_word in result_text:
                result_text = result_text.replace(old_word, new_word)
                changes_made += 1
        
        # åº”ç”¨æ¨¡å¼æ›¿æ¢
        for pattern, replacement in rules["patterns"]:
            new_text = re.sub(pattern, replacement, result_text)
            if new_text != result_text:
                result_text = new_text
                changes_made += 1
        
        confidence = min(changes_made / 5.0, 1.0)  # åŸºäºä¿®æ”¹æ•°é‡è®¡ç®—ç½®ä¿¡åº¦
        
        return GenerationResult(
            result_text,
            "style_transfer",
            confidence,
            {
                "target_style": target_style,
                "changes_made": changes_made,
                "original_length": len(text),
                "result_length": len(result_text)
            }
        )

class TextGenerationApp:
    """æ–‡æœ¬ç”Ÿæˆæ•™è‚²åº”ç”¨"""
    
    def __init__(self):
        self.generators = {}
        self.generation_history = []
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        self.generators['ngram'] = NGramLanguageModel(n=3)
        self.generators['markov'] = MarkovChainGenerator(order=2)
        self.generators['template'] = TemplateGenerator()
        self.generators['style_transfer'] = TextStyleTransfer()
        
        if HAS_TRANSFORMERS:
            try:
                self.generators['transformer'] = TransformerGenerator()
            except Exception as e:
                print(f"æ— æ³•åˆå§‹åŒ–Transformerç”Ÿæˆå™¨: {e}")
    
    def train_statistical_models(self, texts: List[str] = None):
        """è®­ç»ƒç»Ÿè®¡æ¨¡å‹"""
        if texts is None:
            texts = self._create_sample_texts()
        
        print("è®­ç»ƒç»Ÿè®¡æ–‡æœ¬ç”Ÿæˆæ¨¡å‹...")
        
        # è®­ç»ƒN-gramæ¨¡å‹
        if 'ngram' in self.generators:
            self.generators['ngram'].train(texts)
        
        # è®­ç»ƒé©¬å°”å¯å¤«é“¾
        if 'markov' in self.generators:
            self.generators['markov'].train(texts)
        
        print("ç»Ÿè®¡æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    
    def _create_sample_texts(self) -> List[str]:
        """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ–‡æœ¬"""
        return [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œä¸ºå„è¡Œå„ä¸šå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç®—æ³•ä½¿è®¡ç®—æœºèƒ½å¤Ÿå¤„ç†å¤æ‚çš„ä»»åŠ¡ã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚æ–‡æœ¬ç”Ÿæˆæ˜¯å…¶ä¸­çš„ä¸€ä¸ªå…³é”®æŠ€æœ¯ã€‚",
            "åœ¨æ•™è‚²é¢†åŸŸï¼Œæ™ºèƒ½åŒ–å·¥å…·å¯ä»¥å¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°å­¦ä¹ ã€‚ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®å­¦ç”Ÿçš„å­¦ä¹ ä¹ æƒ¯æä¾›å®šåˆ¶åŒ–å†…å®¹ã€‚",
            "äº‘è®¡ç®—å’Œå¤§æ•°æ®æŠ€æœ¯ä¸ºä¼ä¸šæä¾›äº†å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ã€‚è¿™äº›æŠ€æœ¯ä½¿å¾—å¤„ç†æµ·é‡æ•°æ®æˆä¸ºå¯èƒ½ã€‚",
            "ç§»åŠ¨äº’è”ç½‘çš„æ™®åŠæ”¹å˜äº†äººä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚æ™ºèƒ½æ‰‹æœºæˆä¸ºäº†äººä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ã€‚",
            "ç”µå­å•†åŠ¡å¹³å°åˆ©ç”¨æ¨èç®—æ³•ä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„è´­ç‰©ä½“éªŒã€‚è¿™æé«˜äº†ç”¨æˆ·æ»¡æ„åº¦å’Œå•†ä¸šä»·å€¼ã€‚",
            "ç¤¾äº¤åª’ä½“åˆ†æå¯ä»¥å¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…çš„éœ€æ±‚å’Œåå¥½ã€‚æƒ…æ„Ÿåˆ†ææŠ€æœ¯åœ¨è¿™æ–¹é¢å‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚",
            "æ™ºèƒ½å®¶å±…ç³»ç»Ÿé€šè¿‡ç‰©è”ç½‘æŠ€æœ¯è¿æ¥å„ç§è®¾å¤‡ã€‚è¯­éŸ³åŠ©æ‰‹ä½¿å¾—äººæœºäº¤äº’å˜å¾—æ›´åŠ è‡ªç„¶ã€‚",
            "åœ¨åŒ»ç–—é¢†åŸŸï¼Œäººå·¥æ™ºèƒ½è¾…åŠ©è¯Šæ–­ç³»ç»Ÿæé«˜äº†è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚å›¾åƒè¯†åˆ«æŠ€æœ¯åœ¨åŒ»å­¦å½±åƒåˆ†æä¸­åº”ç”¨å¹¿æ³›ã€‚",
            "è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ç»“åˆäº†è®¡ç®—æœºè§†è§‰ã€ä¼ æ„Ÿå™¨èåˆå’Œè·¯å¾„è§„åˆ’ç­‰å¤šç§æŠ€æœ¯ã€‚è¿™ä»£è¡¨äº†æœªæ¥äº¤é€šçš„å‘å±•æ–¹å‘ã€‚"
        ]
    
    def generate_text(self, method: str, prompt: str = "", **kwargs) -> GenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        if method not in self.generators:
            return GenerationResult("", method, 0.0, {"error": f"æœªçŸ¥çš„ç”Ÿæˆæ–¹æ³•: {method}"})
        
        generator = self.generators[method]
        
        try:
            if method == "template":
                template_category = kwargs.get("template_category", "story_beginning")
                custom_values = kwargs.get("custom_values", {})
                result = generator.generate_text(template_category, custom_values)
            
            elif method == "style_transfer":
                target_style = kwargs.get("target_style", "formal")
                result = generator.transfer_style(prompt, target_style)
            
            elif method == "transformer":
                max_length = kwargs.get("max_length", 100)
                temperature = kwargs.get("temperature", 0.7)
                result = generator.generate_text(prompt, max_length, temperature)
            
            else:  # ngram, markov
                max_length = kwargs.get("max_length", 100)
                result = generator.generate_text(prompt, max_length)
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            self.generation_history.append(result)
            
            return result
        
        except Exception as e:
            return GenerationResult("", method, 0.0, {"error": str(e)})
    
    def compare_generation_methods(self, prompt: str = "ä»Šå¤©å¤©æ°”"):
        """æ¯”è¾ƒä¸åŒç”Ÿæˆæ–¹æ³•"""
        print(f"\nä½¿ç”¨æç¤ºè¯: '{prompt}' æ¯”è¾ƒä¸åŒç”Ÿæˆæ–¹æ³•")
        print("=" * 80)
        
        for method in self.generators.keys():
            if method == "style_transfer":
                continue  # é£æ ¼è¿ç§»éœ€è¦å®Œæ•´æ–‡æœ¬è¾“å…¥
            
            print(f"\n{method.upper()} æ–¹æ³•:")
            print("-" * 50)
            
            try:
                if method == "template":
                    result = self.generate_text(method, template_category="story_beginning")
                elif method == "transformer" and prompt:
                    result = self.generate_text(method, prompt, max_length=50)
                else:
                    result = self.generate_text(method, prompt, max_length=50)
                
                print(f"ç”Ÿæˆæ–‡æœ¬: {result.generated_text}")
                print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
                if result.metadata:
                    print(f"å…ƒæ•°æ®: {result.metadata}")
            
            except Exception as e:
                print(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    def analyze_generation_quality(self, texts: List[str], reference_text: str = None):
        """åˆ†æç”Ÿæˆè´¨é‡"""
        print("\næ–‡æœ¬ç”Ÿæˆè´¨é‡åˆ†æ:")
        print("=" * 60)
        
        metrics = {}
        
        for i, text in enumerate(texts):
            metrics[f"text_{i+1}"] = {
                "length": len(text),
                "word_count": len(text.split()),
                "sentence_count": len(re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)),
                "avg_word_length": np.mean([len(word) for word in text.split()]) if text.split() else 0,
                "uniqueness": len(set(text.split())) / len(text.split()) if text.split() else 0
            }
        
        # åˆ›å»ºå¯è§†åŒ–
        df = pd.DataFrame(metrics).T
        
        plt.figure(figsize=(15, 10))
        
        # æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
        plt.subplot(2, 3, 1)
        plt.bar(range(len(texts)), df['length'])
        plt.title('æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ')
        plt.xlabel('æ–‡æœ¬ç¼–å·')
        plt.ylabel('å­—ç¬¦æ•°')
        
        # è¯æ±‡æ•°é‡åˆ†å¸ƒ
        plt.subplot(2, 3, 2)
        plt.bar(range(len(texts)), df['word_count'])
        plt.title('è¯æ±‡æ•°é‡åˆ†å¸ƒ')
        plt.xlabel('æ–‡æœ¬ç¼–å·')
        plt.ylabel('è¯æ±‡æ•°')
        
        # å¹³å‡è¯é•¿åˆ†å¸ƒ
        plt.subplot(2, 3, 3)
        plt.bar(range(len(texts)), df['avg_word_length'])
        plt.title('å¹³å‡è¯é•¿åˆ†å¸ƒ')
        plt.xlabel('æ–‡æœ¬ç¼–å·')
        plt.ylabel('å¹³å‡è¯é•¿')
        
        # å¥å­æ•°é‡åˆ†å¸ƒ
        plt.subplot(2, 3, 4)
        plt.bar(range(len(texts)), df['sentence_count'])
        plt.title('å¥å­æ•°é‡åˆ†å¸ƒ')
        plt.xlabel('æ–‡æœ¬ç¼–å·')
        plt.ylabel('å¥å­æ•°')
        
        # è¯æ±‡ç‹¬ç‰¹æ€§
        plt.subplot(2, 3, 5)
        plt.bar(range(len(texts)), df['uniqueness'])
        plt.title('è¯æ±‡ç‹¬ç‰¹æ€§')
        plt.xlabel('æ–‡æœ¬ç¼–å·')
        plt.ylabel('ç‹¬ç‰¹æ€§æ¯”ä¾‹')
        
        # ç»¼åˆè´¨é‡é›·è¾¾å›¾
        plt.subplot(2, 3, 6)
        
        # å½’ä¸€åŒ–æŒ‡æ ‡
        normalized_metrics = df.copy()
        for col in normalized_metrics.columns:
            max_val = normalized_metrics[col].max()
            if max_val > 0:
                normalized_metrics[col] = normalized_metrics[col] / max_val
        
        # ç»˜åˆ¶é›·è¾¾å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        avg_metrics = normalized_metrics.mean()
        categories = list(avg_metrics.index)
        values = list(avg_metrics.values)
        
        plt.bar(range(len(categories)), values)
        plt.xticks(range(len(categories)), categories, rotation=45)
        plt.title('å¹³å‡è´¨é‡æŒ‡æ ‡')
        plt.ylabel('å½’ä¸€åŒ–åˆ†æ•°')
        
        plt.tight_layout()
        plt.show()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\nè´¨é‡ç»Ÿè®¡:")
        print(f"å¹³å‡æ–‡æœ¬é•¿åº¦: {df['length'].mean():.1f} å­—ç¬¦")
        print(f"å¹³å‡è¯æ±‡æ•°: {df['word_count'].mean():.1f} è¯")
        print(f"å¹³å‡å¥å­æ•°: {df['sentence_count'].mean():.1f} å¥")
        print(f"å¹³å‡è¯æ±‡ç‹¬ç‰¹æ€§: {df['uniqueness'].mean():.3f}")
    
    def creative_writing_assistant(self, theme: str, style: str = "casual"):
        """åˆ›æ„å†™ä½œè¾…åŠ©"""
        print(f"\nğŸ¨ åˆ›æ„å†™ä½œè¾…åŠ© - ä¸»é¢˜: {theme}, é£æ ¼: {style}")
        print("=" * 60)
        
        # ç”Ÿæˆå¤šç§å¼€å¤´
        print("1. æ•…äº‹å¼€å¤´å»ºè®®:")
        for i in range(3):
            result = self.generate_text("template", template_category="story_beginning")
            print(f"   é€‰é¡¹ {i+1}: {result.generated_text}")
        
        # ç”Ÿæˆå…³é”®è¯
        print(f"\n2. ä¸»é¢˜ç›¸å…³è¯æ±‡å»ºè®®:")
        theme_words = self._generate_theme_words(theme)
        print(f"   {', '.join(theme_words)}")
        
        # ç”Ÿæˆæƒ…èŠ‚å‘å±•
        print(f"\n3. æƒ…èŠ‚å‘å±•å»ºè®®:")
        plot_suggestions = self._generate_plot_suggestions(theme)
        for i, suggestion in enumerate(plot_suggestions, 1):
            print(f"   {i}. {suggestion}")
        
        # é£æ ¼è½¬æ¢ç¤ºä¾‹
        if style != "casual":
            print(f"\n4. {style} é£æ ¼è½¬æ¢ç¤ºä¾‹:")
            sample_text = "è¿™ä¸ªæ•…äº‹å¾ˆæœ‰è¶£ï¼Œä¸»äººå…¬çš„ç»å†è®©äººå°è±¡æ·±åˆ»ã€‚"
            style_result = self.generate_text("style_transfer", sample_text, target_style=style)
            print(f"   åŸæ–‡: {sample_text}")
            print(f"   è½¬æ¢å: {style_result.generated_text}")
    
    def _generate_theme_words(self, theme: str) -> List[str]:
        """æ ¹æ®ä¸»é¢˜ç”Ÿæˆç›¸å…³è¯æ±‡"""
        theme_mappings = {
            "ç§‘å¹»": ["æœªæ¥", "ç§‘æŠ€", "æ˜Ÿçƒ", "æœºå™¨äºº", "æ—¶ç©º", "æ¢ç´¢"],
            "çˆ±æƒ…": ["æµªæ¼«", "é‚‚é€…", "å¿ƒåŠ¨", "æ‰¿è¯º", "æ€å¿µ", "æ°¸æ’"],
            "å†’é™©": ["æ—…ç¨‹", "æŒ‘æˆ˜", "å‹‡æ°”", "å‘ç°", "å±é™©", "æˆé•¿"],
            "æ‚¬ç–‘": ["è°œå›¢", "çº¿ç´¢", "çœŸç›¸", "éšç§˜", "è°ƒæŸ¥", "æ­éœ²"],
            "å¥‡å¹»": ["é­”æ³•", "ç²¾çµ", "é¾™æ—", "æ³•æœ¯", "é­”æ³•", "å¼‚ä¸–ç•Œ"]
        }
        
        return theme_mappings.get(theme, ["æ•…äº‹", "æƒ…èŠ‚", "äººç‰©", "èƒŒæ™¯", "å‘å±•", "ç»“å±€"])
    
    def _generate_plot_suggestions(self, theme: str) -> List[str]:
        """ç”Ÿæˆæƒ…èŠ‚å»ºè®®"""
        plot_templates = {
            "ç§‘å¹»": [
                "ä¸»äººå…¬å‘ç°äº†æ¥è‡ªæœªæ¥çš„ä¿¡æ¯",
                "äººå·¥æ™ºèƒ½å¼€å§‹è´¨ç–‘è‡ªå·±çš„å­˜åœ¨",
                "æ—¶é—´æ—…è¡Œè€…æ”¹å˜äº†å†å²è¿›ç¨‹"
            ],
            "çˆ±æƒ…": [
                "ä¸¤ä¸ªäººåœ¨æ„å¤–çš„æƒ…å†µä¸‹ç›¸é‡",
                "è¯¯ä¼šå¯¼è‡´äº†åˆ†ç¦»ï¼ŒçœŸç›¸å¸¦æ¥å’Œè§£",
                "è·ç¦»è€ƒéªŒç€ä»–ä»¬çš„æ„Ÿæƒ…"
            ],
            "å†’é™©": [
                "ä¸€å¼ ç¥ç§˜åœ°å›¾å¼•é¢†ç€å†’é™©ä¹‹æ—…",
                "ä¼™ä¼´ä»¬åœ¨å›°å¢ƒä¸­å±•ç°çœŸæ­£å‹è°Š",
                "æœ€å¤§çš„æ•Œäººå…¶å®æ¥è‡ªå†…å¿ƒææƒ§"
            ]
        }
        
        return plot_templates.get(theme, [
            "ä¸»äººå…¬é¢ä¸´é‡è¦é€‰æ‹©",
            "æ„å¤–çš„è½¬æŠ˜æ”¹å˜äº†ä¸€åˆ‡",
            "æœ€ç»ˆçš„çœŸç›¸ä»¤äººéœ‡æƒŠ"
        ])
    
    def run_interactive_demo(self):
        """è¿è¡Œäº¤äº’å¼æ¼”ç¤º"""
        print("\nâœ¨ æ–‡æœ¬ç”Ÿæˆæ•™è‚²åº”ç”¨")
        print("=" * 50)
        print("å¯ç”¨çš„ç”Ÿæˆæ–¹æ³•:")
        for i, method in enumerate(self.generators.keys(), 1):
            print(f"  {i}. {method}")
        
        # è®­ç»ƒç»Ÿè®¡æ¨¡å‹
        print("\næ­£åœ¨è®­ç»ƒç»Ÿè®¡æ¨¡å‹...")
        self.train_statistical_models()
        
        while True:
            print("\né€‰æ‹©æ“ä½œ:")
            print("1. å•ä¸€æ–¹æ³•ç”Ÿæˆ")
            print("2. æ–¹æ³•æ¯”è¾ƒ")
            print("3. æ¨¡æ¿ç”Ÿæˆ")
            print("4. é£æ ¼è½¬æ¢")
            print("5. è´¨é‡åˆ†æ")
            print("6. åˆ›æ„å†™ä½œè¾…åŠ©")
            print("7. æ‰¹é‡ç”Ÿæˆ")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹© (0-7): ").strip()
            
            if choice == '0':
                break
            
            elif choice == '1':
                method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join(self.generators.keys())}): ").strip()
                if method in self.generators:
                    if method == "style_transfer":
                        text = input("è¯·è¾“å…¥è¦è½¬æ¢é£æ ¼çš„æ–‡æœ¬: ").strip()
                        style = input("ç›®æ ‡é£æ ¼ (formal/casual/poetic): ").strip()
                        result = self.generate_text(method, text, target_style=style)
                    elif method == "template":
                        category = input("æ¨¡æ¿ç±»åˆ« (product_review/news_headline/story_beginning): ").strip()
                        result = self.generate_text(method, template_category=category)
                    else:
                        prompt = input("è¯·è¾“å…¥æç¤ºè¯ (å¯é€‰): ").strip()
                        max_length = int(input("æœ€å¤§é•¿åº¦ (é»˜è®¤100): ").strip() or "100")
                        result = self.generate_text(method, prompt, max_length=max_length)
                    
                    print(f"\nç”Ÿæˆç»“æœ:")
                    print(f"æ–‡æœ¬: {result.generated_text}")
                    print(f"æ–¹æ³•: {result.method}")
                    print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
                    if result.metadata:
                        print(f"å…ƒæ•°æ®: {result.metadata}")
                else:
                    print("æ— æ•ˆçš„æ–¹æ³•")
            
            elif choice == '2':
                prompt = input("è¯·è¾“å…¥æç¤ºè¯: ").strip()
                self.compare_generation_methods(prompt)
            
            elif choice == '3':
                print("å¯ç”¨æ¨¡æ¿ç±»åˆ«:")
                print("- product_review: äº§å“è¯„ä»·")
                print("- news_headline: æ–°é—»æ ‡é¢˜")
                print("- story_beginning: æ•…äº‹å¼€å¤´")
                
                category = input("é€‰æ‹©æ¨¡æ¿ç±»åˆ«: ").strip()
                result = self.generate_text("template", template_category=category)
                print(f"\nç”Ÿæˆç»“æœ: {result.generated_text}")
            
            elif choice == '4':
                text = input("è¯·è¾“å…¥è¦è½¬æ¢é£æ ¼çš„æ–‡æœ¬: ").strip()
                if text:
                    print("å¯ç”¨é£æ ¼: formal(æ­£å¼), casual(éšæ„), poetic(è¯—æ„)")
                    style = input("é€‰æ‹©ç›®æ ‡é£æ ¼: ").strip()
                    result = self.generate_text("style_transfer", text, target_style=style)
                    print(f"\nåŸæ–‡: {text}")
                    print(f"è½¬æ¢å: {result.generated_text}")
                    print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
            
            elif choice == '5':
                print("ç”Ÿæˆå¤šä¸ªæ–‡æœ¬è¿›è¡Œè´¨é‡åˆ†æ...")
                texts = []
                for i in range(5):
                    method = random.choice(['ngram', 'markov', 'template'])
                    if method == 'template':
                        result = self.generate_text(method, template_category="story_beginning")
                    else:
                        result = self.generate_text(method, "ä»Šå¤©", max_length=50)
                    texts.append(result.generated_text)
                
                self.analyze_generation_quality(texts)
            
            elif choice == '6':
                theme = input("è¯·è¾“å…¥åˆ›ä½œä¸»é¢˜ (å¦‚: ç§‘å¹», çˆ±æƒ…, å†’é™©): ").strip()
                style = input("è¯·è¾“å…¥é£æ ¼ (formal/casual/poetic): ").strip() or "casual"
                self.creative_writing_assistant(theme, style)
            
            elif choice == '7':
                method = input(f"é€‰æ‹©ç”Ÿæˆæ–¹æ³• ({'/'.join([m for m in self.generators.keys() if m != 'style_transfer'])}): ").strip()
                if method in self.generators and method != 'style_transfer':
                    count = int(input("ç”Ÿæˆæ•°é‡ (1-10): ").strip() or "3")
                    count = min(max(count, 1), 10)
                    
                    print(f"\næ‰¹é‡ç”Ÿæˆ {count} ä¸ªæ–‡æœ¬:")
                    for i in range(count):
                        if method == "template":
                            categories = ["product_review", "news_headline", "story_beginning"]
                            category = random.choice(categories)
                            result = self.generate_text(method, template_category=category)
                        else:
                            result = self.generate_text(method, max_length=80)
                        
                        print(f"\næ–‡æœ¬ {i+1}: {result.generated_text}")
                        print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
                else:
                    print("æ— æ•ˆçš„æ–¹æ³•æˆ–ä¸æ”¯æŒæ‰¹é‡ç”Ÿæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("åˆå§‹åŒ–æ–‡æœ¬ç”Ÿæˆåº”ç”¨...")
    
    app = TextGenerationApp()
    app.run_interactive_demo()

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒ…æ„Ÿåˆ†ææ•™è‚²åº”ç”¨
Sentiment Analysis Educational Application

è¿™ä¸ªåº”ç”¨å±•ç¤ºäº†æƒ…æ„Ÿåˆ†æçš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼š
- åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
- æœºå™¨å­¦ä¹ æƒ…æ„Ÿåˆ†æ
- æ·±åº¦å­¦ä¹ æƒ…æ„Ÿåˆ†æ
- æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ
- æƒ…æ„Ÿå¯è§†åŒ–

This application demonstrates various sentiment analysis techniques:
- Lexicon-based sentiment analysis
- Machine learning sentiment analysis
- Deep learning sentiment analysis
- Sentiment trend analysis
- Sentiment visualization
"""

import os
import sys
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import re
import time
from collections import defaultdict, Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from src.text_vectorizer import TextVectorizer
from src.utils import load_documents

# å°è¯•å¯¼å…¥æ·±åº¦å­¦ä¹ åº“
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False
    print("æç¤º: å®‰è£…transformersåº“ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æƒ…æ„Ÿåˆ†æ: pip install transformers")

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, confusion_matrix
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("æç¤º: å®‰è£…scikit-learnåº“ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ åŠŸèƒ½: pip install scikit-learn")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class SentimentResult:
    """æƒ…æ„Ÿåˆ†æç»“æœ"""
    text: str
    sentiment: str  # positive, negative, neutral
    confidence: float
    method: str
    detailed_scores: Optional[Dict[str, float]] = None

class LexiconSentimentAnalyzer:
    """åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        # ç®€å•çš„ä¸­æ–‡æƒ…æ„Ÿè¯å…¸
        self.positive_words = {
            'å¥½', 'æ£’', 'èµ', 'ä¼˜ç§€', 'å®Œç¾', 'å–œæ¬¢', 'çˆ±', 'å¼€å¿ƒ', 'å¿«ä¹', 'æ»¡æ„',
            'ç²¾å½©', 'ç¾å¥½', 'æƒŠå–œ', 'æ„Ÿè°¢', 'æ¨è', 'å€¼å¾—', 'ä¸é”™', 'å‰å®³', 'æˆåŠŸ', 'èƒœåˆ©'
        }
        
        self.negative_words = {
            'å', 'å·®', 'ç³Ÿç³•', 'è®¨åŒ', 'å¤±æœ›', 'æ„¤æ€’', 'ç”Ÿæ°”', 'éš¾è¿‡', 'ç—›è‹¦', 'çƒ¦æ¼',
            'é—®é¢˜', 'é”™è¯¯', 'å¤±è´¥', 'åƒåœ¾', 'æ— èŠ', 'åæ‚”', 'æŠ±æ€¨', 'éº»çƒ¦', 'å›°éš¾', 'å±é™©'
        }
        
        # ç¨‹åº¦å‰¯è¯æƒé‡
        self.intensifiers = {
            'éå¸¸': 2.0, 'ç‰¹åˆ«': 2.0, 'ååˆ†': 1.8, 'æå…¶': 2.5, 'è¶…çº§': 2.2,
            'å¾ˆ': 1.5, 'æŒº': 1.3, 'æ¯”è¾ƒ': 1.2, 'ç¨å¾®': 0.8, 'æœ‰ç‚¹': 0.9
        }
        
        # å¦å®šè¯
        self.negations = {'ä¸', 'æ²¡', 'æ— ', 'é', 'æœª', 'åˆ«', 'è«', 'å‹¿'}
    
    def analyze(self, text: str) -> SentimentResult:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        words = list(text)  # ç®€å•åˆ†è¯
        
        positive_score = 0
        negative_score = 0
        
        i = 0
        while i < len(words):
            word = words[i]
            
            # æ£€æŸ¥ç¨‹åº¦å‰¯è¯
            intensifier = 1.0
            if word in self.intensifiers:
                intensifier = self.intensifiers[word]
                i += 1
                if i >= len(words):
                    break
                word = words[i]
            
            # æ£€æŸ¥å¦å®šè¯
            negation = False
            if word in self.negations:
                negation = True
                i += 1
                if i >= len(words):
                    break
                word = words[i]
            
            # æ£€æŸ¥æƒ…æ„Ÿè¯
            if word in self.positive_words:
                score = 1.0 * intensifier
                if negation:
                    negative_score += score
                else:
                    positive_score += score
            elif word in self.negative_words:
                score = 1.0 * intensifier
                if negation:
                    positive_score += score
                else:
                    negative_score += score
            
            i += 1
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        total_score = positive_score - negative_score
        
        if total_score > 0.5:
            sentiment = 'positive'
            confidence = min(total_score / 3.0, 1.0)
        elif total_score < -0.5:
            sentiment = 'negative'
            confidence = min(abs(total_score) / 3.0, 1.0)
        else:
            sentiment = 'neutral'
            confidence = 1.0 - abs(total_score) / 2.0
        
        return SentimentResult(
            text=text,
            sentiment=sentiment,
            confidence=confidence,
            method='lexicon',
            detailed_scores={
                'positive': positive_score,
                'negative': negative_score,
                'total': total_score
            }
        )

class MLSentimentAnalyzer:
    """åŸºäºæœºå™¨å­¦ä¹ çš„æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        if not HAS_SKLEARN:
            raise ImportError("éœ€è¦å®‰è£…scikit-learnåº“")
        
        self.vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        self.classifier = LogisticRegression()
        self.is_trained = False
    
    def create_sample_data(self) -> Tuple[List[str], List[str]]:
        """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®"""
        positive_samples = [
            "è¿™ä¸ªäº§å“çœŸçš„å¾ˆå¥½ç”¨ï¼Œæˆ‘å¾ˆæ»¡æ„ï¼",
            "æœåŠ¡æ€åº¦éå¸¸å¥½ï¼Œæ¨èå¤§å®¶æ¥",
            "è´¨é‡ä¸é”™ï¼Œå€¼å¾—è´­ä¹°",
            "æ•ˆæœå¾ˆæ£’ï¼Œè¶…å‡ºé¢„æœŸ",
            "éå¸¸å¼€å¿ƒï¼Œå®Œç¾çš„ä½“éªŒ",
            "å¾ˆå–œæ¬¢è¿™ä¸ªè®¾è®¡ï¼Œå¤ªèµäº†",
            "ç‰©æµå¾ˆå¿«ï¼Œå•†å“è´¨é‡ä¹Ÿå¾ˆå¥½",
            "å®¢æœå¾ˆè€å¿ƒï¼Œè§£å†³äº†æˆ‘çš„é—®é¢˜",
            "æ€§ä»·æ¯”å¾ˆé«˜ï¼Œæ¨è",
            "ç”¨èµ·æ¥å¾ˆèˆ’æœï¼Œå¾ˆæ»¡æ„"
        ]
        
        negative_samples = [
            "è¿™ä¸ªäº§å“è´¨é‡å¤ªå·®äº†ï¼Œå¾ˆå¤±æœ›",
            "æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œä¸æ¨è",
            "å®Œå…¨ä¸å€¼è¿™ä¸ªä»·æ ¼",
            "æ•ˆæœå¾ˆå·®ï¼Œæµªè´¹é’±",
            "å¾ˆç”Ÿæ°”ï¼Œä½“éªŒå¾ˆç³Ÿç³•",
            "è®¾è®¡å¾ˆä¸‘ï¼Œä¸å–œæ¬¢",
            "ç‰©æµå¤ªæ…¢ï¼Œå•†å“è¿˜æœ‰é—®é¢˜",
            "å®¢æœæ€åº¦å¾ˆå·®ï¼Œä¸è§£å†³é—®é¢˜",
            "æ€§ä»·æ¯”å¾ˆä½ï¼Œä¸å»ºè®®è´­ä¹°",
            "ç”¨èµ·æ¥å¾ˆä¸èˆ’æœï¼Œåæ‚”ä¹°äº†"
        ]
        
        neutral_samples = [
            "è¿™æ˜¯ä¸€ä¸ªæ™®é€šçš„äº§å“",
            "æ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰",
            "è¿˜å¯ä»¥å§ï¼Œä¸€èˆ¬èˆ¬",
            "ä»·æ ¼åˆç†ï¼ŒåŠŸèƒ½åŸºæœ¬å¤Ÿç”¨",
            "æ²¡æœ‰æœŸå¾…ä¹Ÿæ²¡æœ‰å¤±æœ›",
            "ä¸­è§„ä¸­çŸ©çš„è¡¨ç°",
            "ç¬¦åˆæè¿°ï¼Œæ²¡æœ‰æƒŠå–œ",
            "å¹³å¹³å¸¸å¸¸ï¼Œèƒ½ç”¨",
            "è¿˜è¡Œï¼Œä¸å¥½ä¸å",
            "ä¸€èˆ¬çš„ä½“éªŒ"
        ]
        
        texts = positive_samples + negative_samples + neutral_samples
        labels = (['positive'] * len(positive_samples) + 
                 ['negative'] * len(negative_samples) + 
                 ['neutral'] * len(neutral_samples))
        
        return texts, labels
    
    def train(self, texts: List[str] = None, labels: List[str] = None):
        """è®­ç»ƒæ¨¡å‹"""
        if texts is None or labels is None:
            texts, labels = self.create_sample_data()
        
        # å‘é‡åŒ–æ–‡æœ¬
        X = self.vectorizer.fit_transform(texts)
        
        # è®­ç»ƒåˆ†ç±»å™¨
        self.classifier.fit(X, labels)
        self.is_trained = True
        
        print(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä½¿ç”¨ {len(texts)} ä¸ªæ ·æœ¬")
    
    def analyze(self, text: str) -> SentimentResult:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        if not self.is_trained:
            self.train()
        
        # å‘é‡åŒ–æ–‡æœ¬
        X = self.vectorizer.transform([text])
        
        # é¢„æµ‹
        prediction = self.classifier.predict(X)[0]
        probabilities = self.classifier.predict_proba(X)[0]
        
        # è·å–ç±»åˆ«
        classes = self.classifier.classes_
        confidence = max(probabilities)
        
        # åˆ›å»ºè¯¦ç»†åˆ†æ•°
        detailed_scores = {cls: prob for cls, prob in zip(classes, probabilities)}
        
        return SentimentResult(
            text=text,
            sentiment=prediction,
            confidence=confidence,
            method='machine_learning',
            detailed_scores=detailed_scores
        )

class TransformerSentimentAnalyzer:
    """åŸºäºTransformerçš„æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self, model_name: str = "cardiffnlp/twitter-roberta-base-sentiment-latest"):
        if not HAS_TRANSFORMERS:
            raise ImportError("éœ€è¦å®‰è£…transformersåº“")
        
        try:
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis", 
                model=model_name,
                return_all_scores=True
            )
            self.model_name = model_name
        except Exception as e:
            print(f"æ— æ³•åŠ è½½æ¨¡å‹ {model_name}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                return_all_scores=True
            )
            self.model_name = "default"
    
    def analyze(self, text: str) -> SentimentResult:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        results = self.sentiment_pipeline(text)
        
        # å¤„ç†ç»“æœ
        if isinstance(results[0], list):
            results = results[0]
        
        # æ‰¾åˆ°æœ€é«˜åˆ†æ•°çš„æ ‡ç­¾
        best_result = max(results, key=lambda x: x['score'])
        
        # æ ‡å‡†åŒ–æ ‡ç­¾
        label_mapping = {
            'POSITIVE': 'positive',
            'NEGATIVE': 'negative',
            'NEUTRAL': 'neutral',
            'LABEL_0': 'negative',
            'LABEL_1': 'neutral',
            'LABEL_2': 'positive'
        }
        
        sentiment = label_mapping.get(best_result['label'], best_result['label'].lower())
        confidence = best_result['score']
        
        # åˆ›å»ºè¯¦ç»†åˆ†æ•°
        detailed_scores = {
            label_mapping.get(r['label'], r['label'].lower()): r['score'] 
            for r in results
        }
        
        return SentimentResult(
            text=text,
            sentiment=sentiment,
            confidence=confidence,
            method=f'transformer_{self.model_name}',
            detailed_scores=detailed_scores
        )

class SentimentAnalysisApp:
    """æƒ…æ„Ÿåˆ†ææ•™è‚²åº”ç”¨"""
    
    def __init__(self):
        self.analyzers = {}
        self.results_history = []
        
        # åˆå§‹åŒ–åˆ†æå™¨
        self.analyzers['lexicon'] = LexiconSentimentAnalyzer()
        
        if HAS_SKLEARN:
            self.analyzers['ml'] = MLSentimentAnalyzer()
        
        if HAS_TRANSFORMERS:
            try:
                self.analyzers['transformer'] = TransformerSentimentAnalyzer()
            except Exception as e:
                print(f"æ— æ³•åˆå§‹åŒ–Transformeråˆ†æå™¨: {e}")
    
    def analyze_text(self, text: str, methods: List[str] = None) -> Dict[str, SentimentResult]:
        """ä½¿ç”¨å¤šç§æ–¹æ³•åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        if methods is None:
            methods = list(self.analyzers.keys())
        
        results = {}
        for method in methods:
            if method in self.analyzers:
                try:
                    result = self.analyzers[method].analyze(text)
                    results[method] = result
                except Exception as e:
                    print(f"æ–¹æ³• {method} åˆ†æå¤±è´¥: {e}")
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        self.results_history.append({
            'text': text,
            'results': results,
            'timestamp': time.time()
        })
        
        return results
    
    def batch_analyze(self, texts: List[str], method: str = 'lexicon') -> List[SentimentResult]:
        """æ‰¹é‡åˆ†ææ–‡æœ¬"""
        if method not in self.analyzers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")
        
        results = []
        for text in texts:
            try:
                result = self.analyzers[method].analyze(text)
                results.append(result)
            except Exception as e:
                print(f"åˆ†ææ–‡æœ¬ '{text[:50]}...' å¤±è´¥: {e}")
                results.append(SentimentResult(
                    text=text,
                    sentiment='neutral',
                    confidence=0.0,
                    method=method
                ))
        
        return results
    
    def compare_methods(self, text: str) -> None:
        """æ¯”è¾ƒä¸åŒæ–¹æ³•çš„åˆ†æç»“æœ"""
        results = self.analyze_text(text)
        
        print(f"\næ–‡æœ¬: {text}")
        print("=" * 60)
        
        for method, result in results.items():
            print(f"\n{method.upper()} æ–¹æ³•:")
            print(f"  æƒ…æ„Ÿ: {result.sentiment}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
            if result.detailed_scores:
                print("  è¯¦ç»†åˆ†æ•°:")
                for label, score in result.detailed_scores.items():
                    print(f"    {label}: {score:.3f}")
    
    def visualize_sentiment_distribution(self, texts: List[str], method: str = 'lexicon'):
        """å¯è§†åŒ–æƒ…æ„Ÿåˆ†å¸ƒ"""
        results = self.batch_analyze(texts, method)
        
        # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_counts = Counter(result.sentiment for result in results)
        confidence_scores = [result.confidence for result in results]
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        axes[0, 0].pie(sentiment_counts.values(), labels=sentiment_counts.keys(), 
                       autopct='%1.1f%%', startangle=90)
        axes[0, 0].set_title(f'æƒ…æ„Ÿåˆ†å¸ƒ ({method})')
        
        # 2. ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
        axes[0, 1].hist(confidence_scores, bins=20, alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('ç½®ä¿¡åº¦')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        
        # 3. æƒ…æ„Ÿ-ç½®ä¿¡åº¦æ•£ç‚¹å›¾
        sentiments = [result.sentiment for result in results]
        sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}
        sentiment_values = [sentiment_mapping.get(s, 0) for s in sentiments]
        
        axes[1, 0].scatter(sentiment_values, confidence_scores, alpha=0.6)
        axes[1, 0].set_title('æƒ…æ„Ÿä¸ç½®ä¿¡åº¦å…³ç³»')
        axes[1, 0].set_xlabel('æƒ…æ„Ÿ (-1:è´Ÿé¢, 0:ä¸­æ€§, 1:æ­£é¢)')
        axes[1, 0].set_ylabel('ç½®ä¿¡åº¦')
        
        # 4. æƒ…æ„Ÿå¼ºåº¦åˆ†æ
        positive_confidences = [r.confidence for r in results if r.sentiment == 'positive']
        negative_confidences = [r.confidence for r in results if r.sentiment == 'negative']
        neutral_confidences = [r.confidence for r in results if r.sentiment == 'neutral']
        
        data_to_plot = []
        labels = []
        if positive_confidences:
            data_to_plot.append(positive_confidences)
            labels.append('æ­£é¢')
        if negative_confidences:
            data_to_plot.append(negative_confidences)
            labels.append('è´Ÿé¢')
        if neutral_confidences:
            data_to_plot.append(neutral_confidences)
            labels.append('ä¸­æ€§')
        
        if data_to_plot:
            axes[1, 1].boxplot(data_to_plot, labels=labels)
            axes[1, 1].set_title('å„æƒ…æ„Ÿç±»åˆ«ç½®ä¿¡åº¦åˆ†å¸ƒ')
            axes[1, 1].set_ylabel('ç½®ä¿¡åº¦')
        
        plt.tight_layout()
        plt.show()
    
    def sentiment_trend_analysis(self, texts: List[str], method: str = 'lexicon'):
        """æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ"""
        results = self.batch_analyze(texts, method)
        
        # è®¡ç®—æƒ…æ„Ÿåˆ†æ•°ï¼ˆæ­£é¢=1ï¼Œä¸­æ€§=0ï¼Œè´Ÿé¢=-1ï¼‰
        sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}
        sentiment_scores = []
        
        for result in results:
            base_score = sentiment_mapping.get(result.sentiment, 0)
            weighted_score = base_score * result.confidence
            sentiment_scores.append(weighted_score)
        
        # è®¡ç®—æ»‘åŠ¨å¹³å‡
        window_size = min(5, len(sentiment_scores))
        if window_size > 1:
            moving_avg = []
            for i in range(len(sentiment_scores)):
                start = max(0, i - window_size + 1)
                end = i + 1
                avg = np.mean(sentiment_scores[start:end])
                moving_avg.append(avg)
        else:
            moving_avg = sentiment_scores
        
        # ç»˜åˆ¶è¶‹åŠ¿å›¾
        plt.figure(figsize=(12, 6))
        
        x = range(len(sentiment_scores))
        plt.plot(x, sentiment_scores, 'o-', alpha=0.6, label='åŸå§‹æƒ…æ„Ÿåˆ†æ•°')
        plt.plot(x, moving_avg, 'r-', linewidth=2, label=f'æ»‘åŠ¨å¹³å‡ (çª—å£={window_size})')
        
        plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        plt.fill_between(x, sentiment_scores, 0, 
                        where=np.array(sentiment_scores) > 0, 
                        color='green', alpha=0.3, label='æ­£é¢åŒºåŸŸ')
        plt.fill_between(x, sentiment_scores, 0, 
                        where=np.array(sentiment_scores) < 0, 
                        color='red', alpha=0.3, label='è´Ÿé¢åŒºåŸŸ')
        
        plt.title(f'æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ ({method})')
        plt.xlabel('æ–‡æœ¬åºå·')
        plt.ylabel('æƒ…æ„Ÿåˆ†æ•°')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\næƒ…æ„Ÿè¶‹åŠ¿ç»Ÿè®¡ ({method}):")
        print(f"å¹³å‡æƒ…æ„Ÿåˆ†æ•°: {np.mean(sentiment_scores):.3f}")
        print(f"æƒ…æ„Ÿåˆ†æ•°æ ‡å‡†å·®: {np.std(sentiment_scores):.3f}")
        print(f"æœ€å¤§æƒ…æ„Ÿåˆ†æ•°: {np.max(sentiment_scores):.3f}")
        print(f"æœ€å°æƒ…æ„Ÿåˆ†æ•°: {np.min(sentiment_scores):.3f}")
        
        # è¶‹åŠ¿æ–¹å‘
        if len(sentiment_scores) > 1:
            trend = np.polyfit(range(len(sentiment_scores)), sentiment_scores, 1)[0]
            if trend > 0.01:
                trend_desc = "ä¸Šå‡"
            elif trend < -0.01:
                trend_desc = "ä¸‹é™"
            else:
                trend_desc = "å¹³ç¨³"
            print(f"æ•´ä½“è¶‹åŠ¿: {trend_desc} (æ–œç‡: {trend:.4f})")
    
    def run_interactive_demo(self):
        """è¿è¡Œäº¤äº’å¼æ¼”ç¤º"""
        print("\nğŸ­ æƒ…æ„Ÿåˆ†ææ•™è‚²åº”ç”¨")
        print("=" * 50)
        print("å¯ç”¨çš„åˆ†ææ–¹æ³•:")
        for i, method in enumerate(self.analyzers.keys(), 1):
            print(f"  {i}. {method}")
        
        while True:
            print("\né€‰æ‹©æ“ä½œ:")
            print("1. å•æ–‡æœ¬åˆ†æ")
            print("2. æ–¹æ³•æ¯”è¾ƒ")
            print("3. æ‰¹é‡åˆ†æ")
            print("4. è¶‹åŠ¿åˆ†æ")
            print("5. åŠ è½½æ–‡æ¡£æ•°æ®")
            print("0. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹© (0-5): ").strip()
            
            if choice == '0':
                break
            elif choice == '1':
                text = input("è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
                if text:
                    method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join(self.analyzers.keys())}): ").strip()
                    if method in self.analyzers:
                        result = self.analyzers[method].analyze(text)
                        print(f"\nåˆ†æç»“æœ:")
                        print(f"æƒ…æ„Ÿ: {result.sentiment}")
                        print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
                    else:
                        print("æ— æ•ˆçš„æ–¹æ³•")
            
            elif choice == '2':
                text = input("è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬: ").strip()
                if text:
                    self.compare_methods(text)
            
            elif choice == '3':
                print("è¯·è¾“å…¥å¤šä¸ªæ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ª (è¾“å…¥ç©ºè¡Œç»“æŸ):")
                texts = []
                while True:
                    line = input().strip()
                    if not line:
                        break
                    texts.append(line)
                
                if texts:
                    method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join(self.analyzers.keys())}): ").strip()
                    if method in self.analyzers:
                        self.visualize_sentiment_distribution(texts, method)
                    else:
                        print("æ— æ•ˆçš„æ–¹æ³•")
            
            elif choice == '4':
                print("è¯·è¾“å…¥å¤šä¸ªæ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ª (è¾“å…¥ç©ºè¡Œç»“æŸ):")
                texts = []
                while True:
                    line = input().strip()
                    if not line:
                        break
                    texts.append(line)
                
                if texts:
                    method = input(f"é€‰æ‹©æ–¹æ³• ({'/'.join(self.analyzers.keys())}): ").strip()
                    if method in self.analyzers:
                        self.sentiment_trend_analysis(texts, method)
                    else:
                        print("æ— æ•ˆçš„æ–¹æ³•")
            
            elif choice == '5':
                try:
                    documents = load_documents('data/sample_documents.json')
                    texts = [doc['content'] for doc in documents[:10]]  # å–å‰10ä¸ªæ–‡æ¡£
                    print(f"åŠ è½½äº† {len(texts)} ä¸ªæ–‡æ¡£")
                    
                    method = input(f"é€‰æ‹©åˆ†ææ–¹æ³• ({'/'.join(self.analyzers.keys())}): ").strip()
                    if method in self.analyzers:
                        print("æ­£åœ¨åˆ†æ...")
                        self.visualize_sentiment_distribution(texts, method)
                        self.sentiment_trend_analysis(texts, method)
                    else:
                        print("æ— æ•ˆçš„æ–¹æ³•")
                except Exception as e:
                    print(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æåº”ç”¨...")
    
    app = SentimentAnalysisApp()
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_texts = [
        "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼Œæˆ‘éå¸¸æ»¡æ„ï¼",
        "è´¨é‡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·æ ¼",
        "è¿˜å¯ä»¥å§ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„",
        "è¶…çº§å–œæ¬¢ï¼Œæ¨èå¤§å®¶è´­ä¹°",
        "æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œå¾ˆå¤±æœ›",
        "ä»·æ ¼åˆç†ï¼ŒåŠŸèƒ½å¤Ÿç”¨",
        "éå¸¸å¼€å¿ƒï¼Œè¶…å‡ºäº†æˆ‘çš„æœŸå¾…",
        "æœ‰ç‚¹å°é—®é¢˜ï¼Œä½†æ€»ä½“è¿˜è¡Œ",
        "å®Œç¾çš„ä½“éªŒï¼Œäº”æ˜Ÿå¥½è¯„ï¼",
        "ä¸å¤ªæ»¡æ„ï¼Œæ„Ÿè§‰è¢«éª—äº†"
    ]
    
    print("\nğŸ¯ æ¼”ç¤º: æ‰¹é‡æƒ…æ„Ÿåˆ†æ")
    print("=" * 40)
    
    # å¦‚æœæœ‰å¤šä¸ªåˆ†æå™¨ï¼Œæ¯”è¾ƒä¸åŒæ–¹æ³•
    if len(app.analyzers) > 1:
        print("\næ¯”è¾ƒä¸åŒæ–¹æ³•çš„åˆ†æç»“æœ:")
        test_text = "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼Œæˆ‘éå¸¸æ»¡æ„ï¼"
        app.compare_methods(test_text)
    
    # å¯è§†åŒ–æƒ…æ„Ÿåˆ†å¸ƒ
    print("\nç”Ÿæˆæƒ…æ„Ÿåˆ†æå¯è§†åŒ–...")
    app.visualize_sentiment_distribution(sample_texts)
    
    # æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ
    print("\nè¿›è¡Œæƒ…æ„Ÿè¶‹åŠ¿åˆ†æ...")
    app.sentiment_trend_analysis(sample_texts)
    
    # è¿è¡Œäº¤äº’å¼æ¼”ç¤º
    app.run_interactive_demo()

if __name__ == "__main__":
    main()

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1325ab2e",
   "metadata": {},
   "source": [
    "# 向量搜索基础教程\n",
    "# Vector Search Basics Tutorial\n",
    "\n",
    "这个笔记本将介绍向量搜索的基本概念和操作。\n",
    "\n",
    "## 学习目标\n",
    "- 理解向量的基本概念\n",
    "- 学习向量操作和相似度计算\n",
    "- 使用基本向量搜索功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c75841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.basic_vector_search import BasicVectorSearch\n",
    "from src.utils import visualize_vectors, plot_similarity_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ca3b2",
   "metadata": {},
   "source": [
    "## 1. 向量基础\n",
    "\n",
    "向量是机器学习和信息检索的基础。让我们从简单的向量开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一些示例向量\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "vector3 = np.array([1, 1, 1])\n",
    "\n",
    "print(\"向量1:\", vector1)\n",
    "print(\"向量2:\", vector2)\n",
    "print(\"向量3:\", vector3)\n",
    "\n",
    "# 向量的维度\n",
    "print(f\"\\n向量维度: {len(vector1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f443eb",
   "metadata": {},
   "source": [
    "## 2. 初始化向量搜索系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建向量搜索实例\n",
    "search_engine = BasicVectorSearch()\n",
    "\n",
    "# 添加向量到索引\n",
    "vectors = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [1, 1, 1],\n",
    "    [2, 3, 4],\n",
    "    [0, 1, 2]\n",
    "])\n",
    "\n",
    "search_engine.add_vectors(vectors)\n",
    "print(f\"已添加 {len(vectors)} 个向量到搜索引擎\")\n",
    "print(f\"索引大小: {search_engine.get_index_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27178b14",
   "metadata": {},
   "source": [
    "## 3. 相似度计算\n",
    "\n",
    "让我们探索不同的相似度计算方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询向量\n",
    "query_vector = np.array([2, 2, 2])\n",
    "\n",
    "# 使用不同相似度度量进行搜索\n",
    "print(\"查询向量:\", query_vector)\n",
    "print(\"\\n=== 余弦相似度搜索 ===\")\n",
    "cosine_results = search_engine.search(query_vector, k=3, metric='cosine')\n",
    "for i, (idx, similarity) in enumerate(cosine_results):\n",
    "    print(f\"{i+1}. 向量索引 {idx}, 相似度: {similarity:.3f}, 向量: {vectors[idx]}\")\n",
    "\n",
    "print(\"\\n=== 欧几里得距离搜索 ===\")\n",
    "euclidean_results = search_engine.search(query_vector, k=3, metric='euclidean')\n",
    "for i, (idx, distance) in enumerate(euclidean_results):\n",
    "    print(f\"{i+1}. 向量索引 {idx}, 距离: {distance:.3f}, 向量: {vectors[idx]}\")\n",
    "\n",
    "print(\"\\n=== 曼哈顿距离搜索 ===\")\n",
    "manhattan_results = search_engine.search(query_vector, k=3, metric='manhattan')\n",
    "for i, (idx, distance) in enumerate(manhattan_results):\n",
    "    print(f\"{i+1}. 向量索引 {idx}, 距离: {distance:.3f}, 向量: {vectors[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b2ac4",
   "metadata": {},
   "source": [
    "## 4. 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a35e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化向量（仅使用前两个维度）\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 绘制索引中的向量\n",
    "plt.scatter(vectors[:, 0], vectors[:, 1], c='blue', s=100, label='索引向量', alpha=0.7)\n",
    "for i, vec in enumerate(vectors):\n",
    "    plt.annotate(f'V{i}', (vec[0], vec[1]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# 绘制查询向量\n",
    "plt.scatter(query_vector[0], query_vector[1], c='red', s=150, label='查询向量', marker='*')\n",
    "plt.annotate('Query', (query_vector[0], query_vector[1]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('维度 1')\n",
    "plt.ylabel('维度 2')\n",
    "plt.title('向量分布可视化')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6dea6c",
   "metadata": {},
   "source": [
    "## 5. 性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成更大的数据集进行性能测试\n",
    "large_vectors = np.random.rand(1000, 10)  # 1000个10维向量\n",
    "large_search_engine = BasicVectorSearch()\n",
    "large_search_engine.add_vectors(large_vectors)\n",
    "\n",
    "# 性能基准测试\n",
    "query = np.random.rand(10)\n",
    "benchmark_results = large_search_engine.benchmark_search(query, k=10, num_queries=100)\n",
    "\n",
    "print(\"性能基准测试结果:\")\n",
    "for metric, stats in benchmark_results.items():\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  平均时间: {stats['avg_time']:.4f}秒\")\n",
    "    print(f\"  最小时间: {stats['min_time']:.4f}秒\")\n",
    "    print(f\"  最大时间: {stats['max_time']:.4f}秒\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c77b0e",
   "metadata": {},
   "source": [
    "## 6. 总结\n",
    "\n",
    "在这个笔记本中，我们学习了：\n",
    "\n",
    "1. **向量基础**: 什么是向量以及如何表示\n",
    "2. **向量搜索**: 如何构建和使用基本向量搜索系统\n",
    "3. **相似度度量**: 不同相似度计算方法的差异\n",
    "4. **可视化**: 如何可视化向量数据\n",
    "5. **性能**: 搜索性能的测量和比较\n",
    "\n",
    "下一个笔记本将深入探讨各种相似度度量的数学原理和应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b362614",
   "metadata": {},
   "source": [
    "# 向量搜索基础教程\n",
    "# Vector Search Basics Tutorial\n",
    "\n",
    "本教程将带您了解向量搜索的基础概念，包括:\n",
    "- 向量表示\n",
    "- 相似度度量\n",
    "- 基础搜索算法\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19ec77",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加源代码路径\n",
    "sys.path.append('../src')\n",
    "\n",
    "# 设置绘图样式\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"✅ 库导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bf382",
   "metadata": {},
   "source": [
    "## 2. 什么是向量？\n",
    "\n",
    "向量是数学中的基础概念，在机器学习和信息检索中，我们用向量来表示数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建简单的2D向量示例\n",
    "vector_a = np.array([3, 4])\n",
    "vector_b = np.array([1, 2])\n",
    "vector_c = np.array([-2, 3])\n",
    "\n",
    "print(f\"向量 A: {vector_a}\")\n",
    "print(f\"向量 B: {vector_b}\")\n",
    "print(f\"向量 C: {vector_c}\")\n",
    "\n",
    "# 可视化向量\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.quiver(0, 0, vector_a[0], vector_a[1], angles='xy', scale_units='xy', scale=1, color='red', width=0.005, label='向量 A')\n",
    "plt.quiver(0, 0, vector_b[0], vector_b[1], angles='xy', scale_units='xy', scale=1, color='blue', width=0.005, label='向量 B')\n",
    "plt.quiver(0, 0, vector_c[0], vector_c[1], angles='xy', scale_units='xy', scale=1, color='green', width=0.005, label='向量 C')\n",
    "\n",
    "plt.xlim(-3, 5)\n",
    "plt.ylim(-1, 5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.title('2D 向量可视化')\n",
    "plt.xlabel('X 轴')\n",
    "plt.ylabel('Y 轴')\n",
    "plt.show()\n",
    "\n",
    "# 计算向量的长度（L2范数）\n",
    "print(f\"\\n向量长度:\")\n",
    "print(f\"||A|| = {np.linalg.norm(vector_a):.3f}\")\n",
    "print(f\"||B|| = {np.linalg.norm(vector_b):.3f}\")\n",
    "print(f\"||C|| = {np.linalg.norm(vector_c):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9802d",
   "metadata": {},
   "source": [
    "## 3. 相似度度量\n",
    "\n",
    "相似度度量是向量搜索的核心。让我们学习几种常用的相似度计算方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"计算余弦相似度\"\"\"\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\"计算欧几里得距离\"\"\"\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "\n",
    "def manhattan_distance(v1, v2):\n",
    "    \"\"\"计算曼哈顿距离\"\"\"\n",
    "    return np.sum(np.abs(v1 - v2))\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    \"\"\"计算点积\"\"\"\n",
    "    return np.dot(v1, v2)\n",
    "\n",
    "# 计算向量间的相似度/距离\n",
    "print(\"向量 A 和 B 之间的相似度/距离:\")\n",
    "print(f\"余弦相似度: {cosine_similarity(vector_a, vector_b):.4f}\")\n",
    "print(f\"欧几里得距离: {euclidean_distance(vector_a, vector_b):.4f}\")\n",
    "print(f\"曼哈顿距离: {manhattan_distance(vector_a, vector_b):.4f}\")\n",
    "print(f\"点积: {dot_product(vector_a, vector_b):.4f}\")\n",
    "\n",
    "print(\"\\n向量 A 和 C 之间的相似度/距离:\")\n",
    "print(f\"余弦相似度: {cosine_similarity(vector_a, vector_c):.4f}\")\n",
    "print(f\"欧几里得距离: {euclidean_distance(vector_a, vector_c):.4f}\")\n",
    "print(f\"曼哈顿距离: {manhattan_distance(vector_a, vector_c):.4f}\")\n",
    "print(f\"点积: {dot_product(vector_a, vector_c):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962e11e",
   "metadata": {},
   "source": [
    "## 4. 相似度度量的几何解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49cb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建更多向量来展示不同的相似度\n",
    "angles = np.linspace(0, 2*np.pi, 8, endpoint=False)\n",
    "vectors = np.array([[np.cos(angle), np.sin(angle)] for angle in angles])\n",
    "reference_vector = np.array([1, 0])  # 参考向量\n",
    "\n",
    "# 计算所有向量与参考向量的余弦相似度\n",
    "similarities = [cosine_similarity(reference_vector, v) for v in vectors]\n",
    "\n",
    "# 可视化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 左图: 向量可视化\n",
    "ax1.quiver(0, 0, reference_vector[0], reference_vector[1], \n",
    "           angles='xy', scale_units='xy', scale=1, color='red', width=0.01, label='参考向量')\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(vectors)))\n",
    "for i, (v, sim, color) in enumerate(zip(vectors, similarities, colors)):\n",
    "    ax1.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, \n",
    "               color=color, width=0.005, label=f'向量 {i+1} (sim={sim:.3f})')\n",
    "\n",
    "ax1.set_xlim(-1.5, 1.5)\n",
    "ax1.set_ylim(-1.5, 1.5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_title('向量与参考向量的角度关系')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 右图: 相似度分布\n",
    "ax2.bar(range(1, len(similarities)+1), similarities, color=colors)\n",
    "ax2.set_xlabel('向量编号')\n",
    "ax2.set_ylabel('余弦相似度')\n",
    "ax2.set_title('余弦相似度分布')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察:\")\n",
    "print(\"- 余弦相似度衡量向量之间的角度\")\n",
    "print(\"- 相似度为1表示向量方向完全相同\")\n",
    "print(\"- 相似度为0表示向量垂直\")\n",
    "print(\"- 相似度为-1表示向量方向完全相反\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3da51f",
   "metadata": {},
   "source": [
    "## 5. 高维向量示例\n",
    "\n",
    "在实际应用中，我们通常处理高维向量（几十到几千维）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45625a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成高维向量示例\n",
    "np.random.seed(42)  # 保证结果可重现\n",
    "\n",
    "# 创建一些高维向量\n",
    "vector_dim = 100\n",
    "n_vectors = 1000\n",
    "\n",
    "# 方法1: 随机向量\n",
    "random_vectors = np.random.rand(n_vectors, vector_dim)\n",
    "\n",
    "# 方法2: 正态分布向量\n",
    "normal_vectors = np.random.randn(n_vectors, vector_dim)\n",
    "\n",
    "# 方法3: 稀疏向量（大部分元素为0）\n",
    "sparse_vectors = np.zeros((n_vectors, vector_dim))\n",
    "for i in range(n_vectors):\n",
    "    # 只有10%的元素非零\n",
    "    non_zero_indices = np.random.choice(vector_dim, size=vector_dim//10, replace=False)\n",
    "    sparse_vectors[i, non_zero_indices] = np.random.randn(len(non_zero_indices))\n",
    "\n",
    "print(f\"创建了 {n_vectors} 个 {vector_dim} 维向量\")\n",
    "print(f\"随机向量范围: [{np.min(random_vectors):.3f}, {np.max(random_vectors):.3f}]\")\n",
    "print(f\"正态分布向量范围: [{np.min(normal_vectors):.3f}, {np.max(normal_vectors):.3f}]\")\n",
    "print(f\"稀疏向量非零元素比例: {np.count_nonzero(sparse_vectors) / sparse_vectors.size:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较不同向量类型的相似度分布\n",
    "def compute_pairwise_similarities(vectors, sample_size=100):\n",
    "    \"\"\"计算成对相似度\"\"\"\n",
    "    # 为了效率，只计算前sample_size个向量\n",
    "    sample_vectors = vectors[:sample_size]\n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        for j in range(i+1, sample_size):\n",
    "            sim = cosine_similarity(sample_vectors[i], sample_vectors[j])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# 计算相似度分布\n",
    "random_sims = compute_pairwise_similarities(random_vectors)\n",
    "normal_sims = compute_pairwise_similarities(normal_vectors)\n",
    "sparse_sims = compute_pairwise_similarities(sparse_vectors)\n",
    "\n",
    "# 可视化相似度分布\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(random_sims, bins=30, alpha=0.7, color='blue')\n",
    "axes[0].set_title('随机向量相似度分布')\n",
    "axes[0].set_xlabel('余弦相似度')\n",
    "axes[0].set_ylabel('频次')\n",
    "axes[0].axvline(np.mean(random_sims), color='red', linestyle='--', label=f'均值: {np.mean(random_sims):.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(normal_sims, bins=30, alpha=0.7, color='green')\n",
    "axes[1].set_title('正态分布向量相似度分布')\n",
    "axes[1].set_xlabel('余弦相似度')\n",
    "axes[1].set_ylabel('频次')\n",
    "axes[1].axvline(np.mean(normal_sims), color='red', linestyle='--', label=f'均值: {np.mean(normal_sims):.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].hist(sparse_sims, bins=30, alpha=0.7, color='orange')\n",
    "axes[2].set_title('稀疏向量相似度分布')\n",
    "axes[2].set_xlabel('余弦相似度')\n",
    "axes[2].set_ylabel('频次')\n",
    "axes[2].axvline(np.mean(sparse_sims), color='red', linestyle='--', label=f'均值: {np.mean(sparse_sims):.3f}')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察:\")\n",
    "print(f\"- 随机向量平均相似度: {np.mean(random_sims):.4f}\")\n",
    "print(f\"- 正态分布向量平均相似度: {np.mean(normal_sims):.4f}\")\n",
    "print(f\"- 稀疏向量平均相似度: {np.mean(sparse_sims):.4f}\")\n",
    "print(\"\\n随着维度增加，随机向量趋向于正交（相似度接近0）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cb181",
   "metadata": {},
   "source": [
    "## 6. 基础向量搜索实现\n",
    "\n",
    "现在让我们实现一个简单的向量搜索算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09202a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorSearch:\n",
    "    def __init__(self):\n",
    "        self.vectors = None\n",
    "        self.labels = None\n",
    "    \n",
    "    def add_vectors(self, vectors, labels=None):\n",
    "        \"\"\"添加向量到搜索库\"\"\"\n",
    "        self.vectors = np.array(vectors)\n",
    "        if labels is None:\n",
    "            self.labels = [f\"向量_{i}\" for i in range(len(vectors))]\n",
    "        else:\n",
    "            self.labels = labels\n",
    "        print(f\"添加了 {len(vectors)} 个向量\")\n",
    "    \n",
    "    def search(self, query_vector, top_k=5):\n",
    "        \"\"\"搜索最相似的向量\"\"\"\n",
    "        if self.vectors is None:\n",
    "            raise ValueError(\"请先添加向量\")\n",
    "        \n",
    "        # 计算查询向量与所有向量的相似度\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            sim = cosine_similarity(query_vector, vector)\n",
    "            similarities.append((i, sim, self.labels[i]))\n",
    "        \n",
    "        # 按相似度排序\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return similarities[:top_k]\n",
    "\n",
    "# 测试搜索功能\n",
    "search_engine = SimpleVectorSearch()\n",
    "\n",
    "# 使用前面生成的随机向量\n",
    "sample_vectors = random_vectors[:100]  # 使用100个向量作为搜索库\n",
    "sample_labels = [f\"文档_{i:03d}\" for i in range(100)]\n",
    "\n",
    "search_engine.add_vectors(sample_vectors, sample_labels)\n",
    "\n",
    "# 创建查询向量\n",
    "query = np.random.rand(vector_dim)\n",
    "print(f\"\\n查询向量维度: {len(query)}\")\n",
    "\n",
    "# 执行搜索\n",
    "results = search_engine.search(query, top_k=5)\n",
    "\n",
    "print(\"\\n搜索结果 (Top 5):\")\n",
    "for rank, (idx, similarity, label) in enumerate(results, 1):\n",
    "    print(f\"{rank:2d}. {label}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2b68a",
   "metadata": {},
   "source": [
    "## 7. 向量归一化的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5276a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建不同尺度的向量\n",
    "vector_small = np.array([0.1, 0.2])\n",
    "vector_large = np.array([10, 20])\n",
    "vector_medium = np.array([1, 2])\n",
    "\n",
    "print(\"原始向量:\")\n",
    "print(f\"小向量: {vector_small}, 长度: {np.linalg.norm(vector_small):.3f}\")\n",
    "print(f\"中向量: {vector_medium}, 长度: {np.linalg.norm(vector_medium):.3f}\")\n",
    "print(f\"大向量: {vector_large}, 长度: {np.linalg.norm(vector_large):.3f}\")\n",
    "\n",
    "# 计算余弦相似度（注意它们方向相同）\n",
    "print(\"\\n余弦相似度（方向相同的向量）:\")\n",
    "print(f\"小-中: {cosine_similarity(vector_small, vector_medium):.4f}\")\n",
    "print(f\"小-大: {cosine_similarity(vector_small, vector_large):.4f}\")\n",
    "print(f\"中-大: {cosine_similarity(vector_medium, vector_large):.4f}\")\n",
    "\n",
    "# 计算点积（受向量长度影响）\n",
    "print(\"\\n点积（受长度影响）:\")\n",
    "print(f\"小-中: {np.dot(vector_small, vector_medium):.4f}\")\n",
    "print(f\"小-大: {np.dot(vector_small, vector_large):.4f}\")\n",
    "print(f\"中-大: {np.dot(vector_medium, vector_large):.4f}\")\n",
    "\n",
    "# 归一化向量\n",
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "vector_small_norm = normalize(vector_small)\n",
    "vector_medium_norm = normalize(vector_medium)\n",
    "vector_large_norm = normalize(vector_large)\n",
    "\n",
    "print(\"\\n归一化后的向量:\")\n",
    "print(f\"小向量: {vector_small_norm}, 长度: {np.linalg.norm(vector_small_norm):.3f}\")\n",
    "print(f\"中向量: {vector_medium_norm}, 长度: {np.linalg.norm(vector_medium_norm):.3f}\")\n",
    "print(f\"大向量: {vector_large_norm}, 长度: {np.linalg.norm(vector_large_norm):.3f}\")\n",
    "\n",
    "print(\"\\n归一化后的点积（等于余弦相似度）:\")\n",
    "print(f\"小-中: {np.dot(vector_small_norm, vector_medium_norm):.4f}\")\n",
    "print(f\"小-大: {np.dot(vector_small_norm, vector_large_norm):.4f}\")\n",
    "print(f\"中-大: {np.dot(vector_medium_norm, vector_large_norm):.4f}\")\n",
    "\n",
    "print(\"\\n结论: 对于方向相同但长度不同的向量，归一化后点积等于余弦相似度\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37402a30",
   "metadata": {},
   "source": [
    "## 8. 实践练习\n",
    "\n",
    "让我们通过一个实际的例子来应用学到的知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c182822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟文档向量搜索\n",
    "# 假设我们有一些文档，每个文档用特征向量表示\n",
    "\n",
    "# 创建模拟文档向量（每个维度代表一个词的重要性）\n",
    "np.random.seed(123)\n",
    "n_docs = 50\n",
    "n_features = 20  # 简化的特征空间\n",
    "\n",
    "# 文档类型: 科技、体育、艺术\n",
    "doc_types = ['科技', '体育', '艺术']\n",
    "doc_labels = []\n",
    "doc_vectors = []\n",
    "\n",
    "for i in range(n_docs):\n",
    "    doc_type = doc_types[i % 3]\n",
    "    \n",
    "    if doc_type == '科技':\n",
    "        # 科技文档在前7个特征上有较高值\n",
    "        vector = np.concatenate([\n",
    "            np.random.uniform(0.5, 1.0, 7),  # 科技相关特征\n",
    "            np.random.uniform(0.0, 0.3, 13)  # 其他特征\n",
    "        ])\n",
    "    elif doc_type == '体育':\n",
    "        # 体育文档在中间7个特征上有较高值\n",
    "        vector = np.concatenate([\n",
    "            np.random.uniform(0.0, 0.3, 7),   # 科技特征\n",
    "            np.random.uniform(0.5, 1.0, 7),   # 体育相关特征\n",
    "            np.random.uniform(0.0, 0.3, 6)    # 艺术特征\n",
    "        ])\n",
    "    else:  # 艺术\n",
    "        # 艺术文档在后6个特征上有较高值\n",
    "        vector = np.concatenate([\n",
    "            np.random.uniform(0.0, 0.3, 14),  # 其他特征\n",
    "            np.random.uniform(0.5, 1.0, 6)    # 艺术相关特征\n",
    "        ])\n",
    "    \n",
    "    doc_vectors.append(vector)\n",
    "    doc_labels.append(f\"{doc_type}文档_{i:02d}\")\n",
    "\n",
    "doc_vectors = np.array(doc_vectors)\n",
    "\n",
    "print(f\"创建了 {n_docs} 个文档向量，每个 {n_features} 维\")\n",
    "print(f\"文档类型分布: {len([l for l in doc_labels if '科技' in l])} 科技, \"\n",
    "      f\"{len([l for l in doc_labels if '体育' in l])} 体育, \"\n",
    "      f\"{len([l for l in doc_labels if '艺术' in l])} 艺术\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化文档向量的特征分布\n",
    "tech_docs = [i for i, label in enumerate(doc_labels) if '科技' in label]\n",
    "sports_docs = [i for i, label in enumerate(doc_labels) if '体育' in label]\n",
    "art_docs = [i for i, label in enumerate(doc_labels) if '艺术' in label]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 计算每类文档的平均特征值\n",
    "tech_mean = np.mean(doc_vectors[tech_docs], axis=0)\n",
    "sports_mean = np.mean(doc_vectors[sports_docs], axis=0)\n",
    "art_mean = np.mean(doc_vectors[art_docs], axis=0)\n",
    "\n",
    "plt.plot(tech_mean, 'o-', label='科技文档平均', color='blue')\n",
    "plt.plot(sports_mean, 's-', label='体育文档平均', color='green')\n",
    "plt.plot(art_mean, '^-', label='艺术文档平均', color='red')\n",
    "\n",
    "plt.xlabel('特征维度')\n",
    "plt.ylabel('特征值')\n",
    "plt.title('不同类型文档的特征分布')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 创建搜索引擎并添加文档\n",
    "doc_search = SimpleVectorSearch()\n",
    "doc_search.add_vectors(doc_vectors, doc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同类型的查询\n",
    "def test_query(query_vector, query_name):\n",
    "    print(f\"\\n=== {query_name} ===\")\n",
    "    results = doc_search.search(query_vector, top_k=5)\n",
    "    \n",
    "    for rank, (idx, similarity, label) in enumerate(results, 1):\n",
    "        print(f\"{rank}. {label}: {similarity:.4f}\")\n",
    "    \n",
    "    # 统计结果中各类型文档的数量\n",
    "    tech_count = sum(1 for _, _, label in results if '科技' in label)\n",
    "    sports_count = sum(1 for _, _, label in results if '体育' in label)\n",
    "    art_count = sum(1 for _, _, label in results if '艺术' in label)\n",
    "    \n",
    "    print(f\"结果分布: 科技={tech_count}, 体育={sports_count}, 艺术={art_count}\")\n",
    "\n",
    "# 查询1: 科技相关查询\n",
    "tech_query = np.concatenate([\n",
    "    np.ones(7) * 0.8,      # 科技特征高\n",
    "    np.ones(13) * 0.1      # 其他特征低\n",
    "])\n",
    "test_query(tech_query, \"科技查询\")\n",
    "\n",
    "# 查询2: 体育相关查询\n",
    "sports_query = np.concatenate([\n",
    "    np.ones(7) * 0.1,      # 科技特征低\n",
    "    np.ones(7) * 0.8,      # 体育特征高\n",
    "    np.ones(6) * 0.1       # 艺术特征低\n",
    "])\n",
    "test_query(sports_query, \"体育查询\")\n",
    "\n",
    "# 查询3: 艺术相关查询\n",
    "art_query = np.concatenate([\n",
    "    np.ones(14) * 0.1,     # 其他特征低\n",
    "    np.ones(6) * 0.8       # 艺术特征高\n",
    "])\n",
    "test_query(art_query, \"艺术查询\")\n",
    "\n",
    "# 查询4: 混合查询\n",
    "mixed_query = np.ones(20) * 0.5  # 所有特征中等\n",
    "test_query(mixed_query, \"混合查询\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761fe91",
   "metadata": {},
   "source": [
    "## 9. 总结\n",
    "\n",
    "在这个教程中，我们学习了:\n",
    "\n",
    "1. **向量表示**: 如何用数值向量表示数据\n",
    "2. **相似度度量**: 余弦相似度、欧几里得距离、曼哈顿距离等\n",
    "3. **高维向量**: 实际应用中的向量特性\n",
    "4. **向量搜索**: 基础的线性搜索算法\n",
    "5. **归一化**: 向量归一化的重要性\n",
    "6. **实践应用**: 文档搜索的简单示例\n",
    "\n",
    "### 下一步\n",
    "\n",
    "在接下来的教程中，我们将学习:\n",
    "- 更高级的相似度度量方法\n",
    "- 文本向量化技术\n",
    "- 高效的近似搜索算法\n",
    "- 实际应用案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c26740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 尝试修改上面的代码，实验不同的参数设置\n",
    "# 1. 改变文档特征分布\n",
    "# 2. 尝试不同的相似度度量方法\n",
    "# 3. 观察归一化对搜索结果的影响\n",
    "\n",
    "print(\"🎉 教程完成！\")\n",
    "print(\"💡 建议: 尝试修改代码参数，观察结果变化\")\n",
    "print(\"📚 下一步: 学习 02_similarity_metrics.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

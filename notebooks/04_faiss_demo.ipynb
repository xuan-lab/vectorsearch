{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636baa92",
   "metadata": {},
   "source": [
    "# FAISS 高级搜索演示\n",
    "# FAISS Advanced Search Demo\n",
    "\n",
    "这个笔记本演示如何使用FAISS库进行高效的大规模向量搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from src.advanced_search import FAISSSearch, AnnoySearch\n",
    "from src.basic_vector_search import BasicVectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581ec30",
   "metadata": {},
   "source": [
    "## 1. 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd383d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成大规模测试数据\n",
    "np.random.seed(42)\n",
    "\n",
    "# 不同规模的数据集\n",
    "small_data = np.random.randn(1000, 128)    # 1K向量\n",
    "medium_data = np.random.randn(10000, 128)  # 10K向量\n",
    "large_data = np.random.randn(50000, 128)   # 50K向量\n",
    "\n",
    "print(f\"小规模数据: {small_data.shape}\")\n",
    "print(f\"中等规模数据: {medium_data.shape}\")\n",
    "print(f\"大规模数据: {large_data.shape}\")\n",
    "\n",
    "# 查询向量\n",
    "query_vectors = np.random.randn(10, 128)\n",
    "print(f\"查询向量: {query_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388949f",
   "metadata": {},
   "source": [
    "## 2. FAISS vs 基础搜索性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bca166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_search_methods(data, query_vectors, k=10):\n",
    "    \"\"\"比较不同搜索方法的性能\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 基础搜索\n",
    "    print(\"测试基础搜索...\")\n",
    "    basic_search = BasicVectorSearch()\n",
    "    basic_search.add_vectors(data)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for query in query_vectors:\n",
    "        _ = basic_search.search(query, k=k)\n",
    "    basic_time = time.time() - start_time\n",
    "    results['基础搜索'] = basic_time\n",
    "    \n",
    "    # FAISS搜索 (如果可用)\n",
    "    try:\n",
    "        print(\"测试FAISS搜索...\")\n",
    "        faiss_search = FAISSSearch(dimension=data.shape[1])\n",
    "        faiss_search.add_vectors(data)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        _ = faiss_search.batch_search(query_vectors, k=k)\n",
    "        faiss_time = time.time() - start_time\n",
    "        results['FAISS'] = faiss_time\n",
    "    except ImportError:\n",
    "        print(\"FAISS不可用，跳过测试\")\n",
    "        results['FAISS'] = None\n",
    "    \n",
    "    # Annoy搜索 (如果可用)\n",
    "    try:\n",
    "        print(\"测试Annoy搜索...\")\n",
    "        annoy_search = AnnoySearch(dimension=data.shape[1])\n",
    "        annoy_search.add_vectors(data)\n",
    "        annoy_search.build_index()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for query in query_vectors:\n",
    "            _ = annoy_search.search(query, k=k)\n",
    "        annoy_time = time.time() - start_time\n",
    "        results['Annoy'] = annoy_time\n",
    "    except ImportError:\n",
    "        print(\"Annoy不可用，跳过测试\")\n",
    "        results['Annoy'] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 在不同数据规模上进行测试\n",
    "datasets = {\n",
    "    '小规模(1K)': small_data,\n",
    "    '中等规模(10K)': medium_data,\n",
    "    '大规模(50K)': large_data\n",
    "}\n",
    "\n",
    "benchmark_results = {}\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n=== {name} 数据集测试 ===\")\n",
    "    benchmark_results[name] = benchmark_search_methods(data, query_vectors[:5])  # 使用5个查询"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf70cb",
   "metadata": {},
   "source": [
    "## 3. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化性能比较结果\n",
    "methods = ['基础搜索', 'FAISS', 'Annoy']\n",
    "dataset_names = list(benchmark_results.keys())\n",
    "\n",
    "# 准备数据\n",
    "performance_data = {method: [] for method in methods}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for method in methods:\n",
    "        time_taken = benchmark_results[dataset_name].get(method)\n",
    "        performance_data[method].append(time_taken if time_taken is not None else 0)\n",
    "\n",
    "# 绘制性能比较图\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(dataset_names))\n",
    "width = 0.25\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    times = performance_data[method]\n",
    "    if any(t > 0 for t in times):  # 只绘制有数据的方法\n",
    "        plt.bar(x + i * width, times, width, label=method)\n",
    "\n",
    "plt.xlabel('数据集规模')\n",
    "plt.ylabel('搜索时间 (秒)')\n",
    "plt.title('不同搜索方法性能比较')\n",
    "plt.xticks(x + width, dataset_names)\n",
    "plt.legend()\n",
    "plt.yscale('log')  # 使用对数坐标\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印具体数值\n",
    "print(\"\\n性能比较结果 (秒):\")\n",
    "print(\"-\" * 50)\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    for method in methods:\n",
    "        time_taken = benchmark_results[dataset_name].get(method)\n",
    "        if time_taken is not None:\n",
    "            print(f\"  {method}: {time_taken:.4f}秒\")\n",
    "        else:\n",
    "            print(f\"  {method}: 不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d103a24",
   "metadata": {},
   "source": [
    "## 4. FAISS 不同索引类型比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果FAISS可用，测试不同索引类型\n",
    "try:\n",
    "    import faiss\n",
    "    \n",
    "    print(\"测试FAISS不同索引类型...\")\n",
    "    \n",
    "    # 使用中等规模数据\n",
    "    test_data = medium_data\n",
    "    test_queries = query_vectors[:3]\n",
    "    \n",
    "    index_types = {\n",
    "        'Flat (精确)': 'Flat',\n",
    "        'IVF100 (近似)': 'IVF100,Flat', \n",
    "        'LSH (哈希)': 'LSH'\n",
    "    }\n",
    "    \n",
    "    faiss_results = {}\n",
    "    \n",
    "    for name, index_type in index_types.items():\n",
    "        try:\n",
    "            print(f\"\\n测试 {name}...\")\n",
    "            \n",
    "            # 创建索引\n",
    "            dimension = test_data.shape[1]\n",
    "            if index_type == 'Flat':\n",
    "                index = faiss.IndexFlatL2(dimension)\n",
    "            elif index_type == 'IVF100,Flat':\n",
    "                quantizer = faiss.IndexFlatL2(dimension)\n",
    "                index = faiss.IndexIVFFlat(quantizer, dimension, 100)\n",
    "                index.train(test_data.astype('float32'))\n",
    "            elif index_type == 'LSH':\n",
    "                index = faiss.IndexLSH(dimension, 256)\n",
    "            \n",
    "            # 添加向量\n",
    "            index.add(test_data.astype('float32'))\n",
    "            \n",
    "            # 搜索测试\n",
    "            start_time = time.time()\n",
    "            distances, indices = index.search(test_queries.astype('float32'), 10)\n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            faiss_results[name] = {\n",
    "                'time': search_time,\n",
    "                'memory': index.ntotal * 4 * dimension / (1024**2)  # 估算内存使用(MB)\n",
    "            }\n",
    "            \n",
    "            print(f\"  搜索时间: {search_time:.4f}秒\")\n",
    "            print(f\"  估算内存: {faiss_results[name]['memory']:.1f}MB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {name} 测试失败: {e}\")\n",
    "    \n",
    "    # 可视化FAISS索引比较\n",
    "    if faiss_results:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        names = list(faiss_results.keys())\n",
    "        times = [faiss_results[name]['time'] for name in names]\n",
    "        memories = [faiss_results[name]['memory'] for name in names]\n",
    "        \n",
    "        # 搜索时间比较\n",
    "        ax1.bar(names, times)\n",
    "        ax1.set_ylabel('搜索时间 (秒)')\n",
    "        ax1.set_title('FAISS索引类型 - 搜索时间')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 内存使用比较\n",
    "        ax2.bar(names, memories)\n",
    "        ax2.set_ylabel('内存使用 (MB)')\n",
    "        ax2.set_title('FAISS索引类型 - 内存使用')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"FAISS不可用，跳过详细测试\")\n",
    "    print(\"安装FAISS: pip install faiss-cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1884994",
   "metadata": {},
   "source": [
    "## 5. 实际应用场景模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟实际应用场景：文档搜索系统\n",
    "print(\"=== 文档搜索系统模拟 ===\")\n",
    "\n",
    "# 生成模拟文档向量（表示文档特征）\n",
    "num_documents = 10000\n",
    "vector_dim = 384  # 典型的sentence embedding维度\n",
    "\n",
    "# 创建一些聚类中心（代表不同主题）\n",
    "num_clusters = 20\n",
    "cluster_centers = np.random.randn(num_clusters, vector_dim)\n",
    "\n",
    "# 生成围绕聚类中心的文档向量\n",
    "document_vectors = []\n",
    "document_labels = []\n",
    "\n",
    "for i in range(num_documents):\n",
    "    cluster_id = np.random.randint(0, num_clusters)\n",
    "    # 在聚类中心附近生成向量\n",
    "    noise = np.random.randn(vector_dim) * 0.3\n",
    "    doc_vector = cluster_centers[cluster_id] + noise\n",
    "    document_vectors.append(doc_vector)\n",
    "    document_labels.append(f\"主题{cluster_id}\")\n",
    "\n",
    "document_vectors = np.array(document_vectors)\n",
    "\n",
    "print(f\"生成了 {num_documents} 个文档向量，分属 {num_clusters} 个主题\")\n",
    "print(f\"向量维度: {vector_dim}\")\n",
    "\n",
    "# 创建搜索引擎\n",
    "search_engines = {}\n",
    "\n",
    "# 基础搜索\n",
    "basic_engine = BasicVectorSearch()\n",
    "basic_engine.add_vectors(document_vectors)\n",
    "search_engines['基础搜索'] = basic_engine\n",
    "\n",
    "# FAISS搜索 (如果可用)\n",
    "try:\n",
    "    faiss_engine = FAISSSearch(dimension=vector_dim)\n",
    "    faiss_engine.add_vectors(document_vectors)\n",
    "    search_engines['FAISS'] = faiss_engine\n",
    "except:\n",
    "    print(\"FAISS不可用\")\n",
    "\n",
    "# Annoy搜索 (如果可用)\n",
    "try:\n",
    "    annoy_engine = AnnoySearch(dimension=vector_dim)\n",
    "    annoy_engine.add_vectors(document_vectors)\n",
    "    annoy_engine.build_index()\n",
    "    search_engines['Annoy'] = annoy_engine\n",
    "except:\n",
    "    print(\"Annoy不可用\")\n",
    "\n",
    "print(f\"\\n可用搜索引擎: {list(search_engines.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行搜索测试\n",
    "query_vector = np.random.randn(vector_dim)\n",
    "k = 10\n",
    "\n",
    "print(\"\\n=== 搜索结果比较 ===\")\n",
    "\n",
    "for engine_name, engine in search_engines.items():\n",
    "    print(f\"\\n{engine_name} 搜索结果:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    if hasattr(engine, 'batch_search'):\n",
    "        # FAISS批量搜索\n",
    "        results = engine.batch_search([query_vector], k=k)[0]\n",
    "    else:\n",
    "        # 单个搜索\n",
    "        results = engine.search(query_vector, k=k)\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  搜索时间: {search_time:.4f}秒\")\n",
    "    print(f\"  前5个结果:\")\n",
    "    \n",
    "    for i, (idx, score) in enumerate(results[:5]):\n",
    "        label = document_labels[idx]\n",
    "        print(f\"    {i+1}. 文档{idx} ({label}), 得分: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2698d9c",
   "metadata": {},
   "source": [
    "## 6. 总结和建议\n",
    "\n",
    "### 性能特点:\n",
    "- **基础搜索**: 精确但慢，适合小规模数据\n",
    "- **FAISS**: 快速且灵活，适合大规模数据\n",
    "- **Annoy**: 内存效率高，适合只读场景\n",
    "\n",
    "### 选择建议:\n",
    "- **< 10K向量**: 基础搜索足够\n",
    "- **10K-1M向量**: 使用FAISS\n",
    "- **> 1M向量**: 使用FAISS IVF索引\n",
    "- **内存限制**: 考虑Annoy\n",
    "\n",
    "下一个笔记本将展示完整的应用系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c8010",
   "metadata": {},
   "source": [
    "# FAISS高性能向量搜索演示\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) 是Facebook开发的高效相似性搜索库，专门用于大规模向量搜索。\n",
    "\n",
    "## 学习目标\n",
    "- 理解FAISS的工作原理和优势\n",
    "- 学习不同的FAISS索引类型\n",
    "- 实践FAISS在大规模向量搜索中的应用\n",
    "- 性能对比和优化技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c645ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import faiss\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from src.advanced_search import FAISSSearch, AnnoySearch\n",
    "from src.text_vectorizer import TextVectorizer\n",
    "from src.utils import load_documents, VectorSearchBenchmark\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f50826",
   "metadata": {},
   "source": [
    "## 1. FAISS基础概念\n",
    "\n",
    "FAISS提供多种索引类型，每种都有不同的特点和适用场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例数据集\n",
    "def create_sample_vectors(n_samples=1000, n_features=128, n_clusters=5):\n",
    "    \"\"\"创建示例向量数据集\"\"\"\n",
    "    X, y = make_blobs(n_samples=n_samples, centers=n_clusters, \n",
    "                      n_features=n_features, random_state=42)\n",
    "    # 归一化向量（对于余弦相似度很重要）\n",
    "    X = normalize(X)\n",
    "    return X.astype('float32'), y\n",
    "\n",
    "# 生成测试数据\n",
    "vectors, labels = create_sample_vectors(n_samples=10000, n_features=128)\n",
    "print(f\"生成了 {vectors.shape[0]} 个 {vectors.shape[1]} 维向量\")\n",
    "print(f\"向量类型: {vectors.dtype}\")\n",
    "print(f\"向量范围: [{vectors.min():.3f}, {vectors.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69c15e",
   "metadata": {},
   "source": [
    "## 2. FAISS索引类型介绍\n",
    "\n",
    "让我们演示不同类型的FAISS索引及其特点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be83f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示不同的FAISS索引类型\n",
    "dimension = vectors.shape[1]\n",
    "n_vectors = vectors.shape[0]\n",
    "\n",
    "print(\"FAISS索引类型演示:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Flat索引 - 精确搜索\n",
    "print(\"\\n1. Flat索引 (精确搜索):\")\n",
    "index_flat = faiss.IndexFlatL2(dimension)\n",
    "index_flat.add(vectors)\n",
    "print(f\"   索引中的向量数: {index_flat.ntotal}\")\n",
    "print(f\"   是否训练: {index_flat.is_trained}\")\n",
    "\n",
    "# 2. IVF索引 - 倒排文件索引\n",
    "print(\"\\n2. IVF索引 (近似搜索):\")\n",
    "nlist = 100  # 聚类中心数\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "print(f\"   训练前状态: {index_ivf.is_trained}\")\n",
    "index_ivf.train(vectors)\n",
    "print(f\"   训练后状态: {index_ivf.is_trained}\")\n",
    "index_ivf.add(vectors)\n",
    "print(f\"   索引中的向量数: {index_ivf.ntotal}\")\n",
    "print(f\"   聚类中心数: {nlist}\")\n",
    "\n",
    "# 3. HNSW索引 - 分层可导航小世界图\n",
    "print(\"\\n3. HNSW索引 (图-based搜索):\")\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, 32)  # 32是M参数\n",
    "index_hnsw.add(vectors)\n",
    "print(f\"   索引中的向量数: {index_hnsw.ntotal}\")\n",
    "print(f\"   HNSW M参数: 32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d513c0",
   "metadata": {},
   "source": [
    "## 3. 搜索性能比较\n",
    "\n",
    "比较不同索引类型的搜索速度和准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eec07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能测试函数\n",
    "def benchmark_index(index, query_vectors, k=10, name=\"Unknown\"):\n",
    "    \"\"\"测试索引性能\"\"\"\n",
    "    start_time = time.time()\n",
    "    distances, indices = index.search(query_vectors, k)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'search_time': search_time,\n",
    "        'qps': len(query_vectors) / search_time,  # 每秒查询数\n",
    "        'avg_distance': np.mean(distances),\n",
    "        'distances': distances,\n",
    "        'indices': indices\n",
    "    }\n",
    "\n",
    "# 准备查询向量\n",
    "n_queries = 100\n",
    "query_vectors = vectors[:n_queries].copy()\n",
    "k = 10  # 返回前10个最相似的\n",
    "\n",
    "print(f\"性能测试: {n_queries} 个查询，每个返回 {k} 个结果\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 测试所有索引\n",
    "indices_to_test = [\n",
    "    (index_flat, \"Flat (精确)\"),\n",
    "    (index_ivf, \"IVF (近似)\"),\n",
    "    (index_hnsw, \"HNSW (图-based)\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for index, name in indices_to_test:\n",
    "    result = benchmark_index(index, query_vectors, k, name)\n",
    "    results.append(result)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  搜索时间: {result['search_time']:.4f} 秒\")\n",
    "    print(f\"  QPS: {result['qps']:.1f} 查询/秒\")\n",
    "    print(f\"  平均距离: {result['avg_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化性能比较\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 搜索时间比较\n",
    "plt.subplot(1, 3, 1)\n",
    "names = [r['name'] for r in results]\n",
    "times = [r['search_time'] for r in results]\n",
    "bars1 = plt.bar(names, times, color=['blue', 'orange', 'green'], alpha=0.7)\n",
    "plt.title('搜索时间比较')\n",
    "plt.ylabel('时间 (秒)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, time in zip(bars1, times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{time:.3f}s', ha='center', va='bottom')\n",
    "\n",
    "# QPS比较\n",
    "plt.subplot(1, 3, 2)\n",
    "qps_values = [r['qps'] for r in results]\n",
    "bars2 = plt.bar(names, qps_values, color=['blue', 'orange', 'green'], alpha=0.7)\n",
    "plt.title('查询吞吐量比较')\n",
    "plt.ylabel('QPS (查询/秒)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, qps in zip(bars2, qps_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "             f'{qps:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# 距离分布比较\n",
    "plt.subplot(1, 3, 3)\n",
    "for result in results:\n",
    "    plt.hist(result['distances'].flatten(), bins=30, alpha=0.5, \n",
    "             label=result['name'], density=True)\n",
    "plt.title('距离分布比较')\n",
    "plt.xlabel('距离')\n",
    "plt.ylabel('密度')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f947f",
   "metadata": {},
   "source": [
    "## 4. 准确性分析\n",
    "\n",
    "比较近似搜索方法与精确搜索的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(true_neighbors, found_neighbors, k):\n",
    "    \"\"\"计算召回率\"\"\"\n",
    "    recalls = []\n",
    "    for i in range(len(true_neighbors)):\n",
    "        true_set = set(true_neighbors[i][:k])\n",
    "        found_set = set(found_neighbors[i][:k])\n",
    "        recall = len(true_set.intersection(found_set)) / k\n",
    "        recalls.append(recall)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# 使用Flat索引作为ground truth\n",
    "true_distances, true_indices = index_flat.search(query_vectors, k)\n",
    "\n",
    "print(\"准确性分析 (以Flat索引为基准):\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for result in results[1:]:  # 跳过Flat索引本身\n",
    "    recall = calculate_recall(true_indices, result['indices'], k)\n",
    "    print(f\"\\n{result['name']}:\")\n",
    "    print(f\"  召回率@{k}: {recall:.3f}\")\n",
    "    print(f\"  速度提升: {results[0]['search_time']/result['search_time']:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57131f",
   "metadata": {},
   "source": [
    "## 5. 实际文本搜索应用\n",
    "\n",
    "在真实的文本数据上演示FAISS的应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fadc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载真实文档数据\n",
    "documents = load_documents('../data/sample_documents.json')\n",
    "vectorizer = TextVectorizer()\n",
    "\n",
    "print(\"加载文档数据...\")\n",
    "texts = [doc['content'] for doc in documents]\n",
    "\n",
    "# 使用Sentence Transformers生成向量（如果可用）\n",
    "try:\n",
    "    print(\"使用Sentence Transformers生成向量...\")\n",
    "    doc_vectors = vectorizer.sentence_transformer_vectorize(texts)\n",
    "except:\n",
    "    print(\"Sentence Transformers不可用，使用TF-IDF...\")\n",
    "    doc_vectors = vectorizer.tfidf_vectorize(texts)\n",
    "    # 转换为float32并归一化\n",
    "    doc_vectors = normalize(doc_vectors.toarray().astype('float32'))\n",
    "\n",
    "print(f\"文档向量维度: {doc_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb70251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用我们的FAISSSearch类\n",
    "print(\"初始化FAISS搜索引擎...\")\n",
    "faiss_search = FAISSSearch(vector_dim=doc_vectors.shape[1])\n",
    "faiss_search.add_vectors(doc_vectors)\n",
    "\n",
    "print(f\"FAISS索引中的向量数: {faiss_search.index.ntotal}\")\n",
    "\n",
    "# 测试搜索\n",
    "query_text = \"人工智能技术发展趋势\"\n",
    "print(f\"\\n搜索查询: '{query_text}'\")\n",
    "\n",
    "# 生成查询向量\n",
    "try:\n",
    "    query_vector = vectorizer.sentence_transformer_vectorize([query_text])\n",
    "except:\n",
    "    query_vector = vectorizer.tfidf_vectorize([query_text])\n",
    "    query_vector = normalize(query_vector.toarray().astype('float32'))\n",
    "\n",
    "# 执行搜索\n",
    "start_time = time.time()\n",
    "distances, indices = faiss_search.search(query_vector, k=5)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n搜索结果 (耗时: {search_time:.4f}秒):\")\n",
    "print(\"=\"*50)\n",
    "for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    if idx < len(documents):\n",
    "        doc = documents[idx]\n",
    "        print(f\"{i+1}. {doc['title']}\")\n",
    "        print(f\"   类别: {doc['category']}\")\n",
    "        print(f\"   距离: {dist:.4f}\")\n",
    "        print(f\"   内容: {doc['content'][:100]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffb849",
   "metadata": {},
   "source": [
    "## 6. 大规模数据性能测试\n",
    "\n",
    "测试FAISS在大规模数据上的性能表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同规模的数据集进行测试\n",
    "scales = [1000, 5000, 10000, 50000]\n",
    "dimension = 128\n",
    "results_scale = []\n",
    "\n",
    "print(\"大规模性能测试:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for scale in scales:\n",
    "    print(f\"\\n测试规模: {scale:,} 向量\")\n",
    "    \n",
    "    # 生成数据\n",
    "    large_vectors, _ = create_sample_vectors(n_samples=scale, n_features=dimension)\n",
    "    \n",
    "    # 创建索引并添加向量\n",
    "    start_time = time.time()\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(large_vectors)\n",
    "    build_time = time.time() - start_time\n",
    "    \n",
    "    # 测试搜索性能\n",
    "    query_vecs = large_vectors[:100]  # 使用前100个作为查询\n",
    "    start_time = time.time()\n",
    "    distances, indices = index.search(query_vecs, 10)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    result = {\n",
    "        'scale': scale,\n",
    "        'build_time': build_time,\n",
    "        'search_time': search_time,\n",
    "        'qps': 100 / search_time\n",
    "    }\n",
    "    results_scale.append(result)\n",
    "    \n",
    "    print(f\"  索引构建时间: {build_time:.3f}秒\")\n",
    "    print(f\"  搜索时间: {search_time:.4f}秒\")\n",
    "    print(f\"  QPS: {result['qps']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c29cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化规模性能关系\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "scales_list = [r['scale'] for r in results_scale]\n",
    "build_times = [r['build_time'] for r in results_scale]\n",
    "search_times = [r['search_time'] for r in results_scale]\n",
    "qps_list = [r['qps'] for r in results_scale]\n",
    "\n",
    "# 构建时间 vs 规模\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(scales_list, build_times, 'o-', color='blue', linewidth=2)\n",
    "plt.title('索引构建时间 vs 数据规模')\n",
    "plt.xlabel('向量数量')\n",
    "plt.ylabel('构建时间 (秒)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 搜索时间 vs 规模\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(scales_list, search_times, 'o-', color='orange', linewidth=2)\n",
    "plt.title('搜索时间 vs 数据规模')\n",
    "plt.xlabel('向量数量')\n",
    "plt.ylabel('搜索时间 (秒)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# QPS vs 规模\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(scales_list, qps_list, 'o-', color='green', linewidth=2)\n",
    "plt.title('查询吞吐量 vs 数据规模')\n",
    "plt.xlabel('向量数量')\n",
    "plt.ylabel('QPS (查询/秒)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd701e7",
   "metadata": {},
   "source": [
    "## 7. FAISS高级功能\n",
    "\n",
    "演示FAISS的一些高级功能，如索引持久化、量化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecca3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 索引持久化\n",
    "print(\"索引持久化演示:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# 创建一个索引\n",
    "test_vectors, _ = create_sample_vectors(1000, 64)\n",
    "index = faiss.IndexFlatL2(64)\n",
    "index.add(test_vectors)\n",
    "\n",
    "print(f\"原始索引中的向量数: {index.ntotal}\")\n",
    "\n",
    "# 保存索引\n",
    "index_path = '../data/faiss_index.bin'\n",
    "faiss.write_index(index, index_path)\n",
    "print(f\"索引已保存到: {index_path}\")\n",
    "\n",
    "# 加载索引\n",
    "loaded_index = faiss.read_index(index_path)\n",
    "print(f\"加载的索引中的向量数: {loaded_index.ntotal}\")\n",
    "\n",
    "# 验证索引一致性\n",
    "query = test_vectors[:1]\n",
    "dist1, idx1 = index.search(query, 5)\n",
    "dist2, idx2 = loaded_index.search(query, 5)\n",
    "\n",
    "print(f\"原始索引结果: {idx1[0][:3]}\")\n",
    "print(f\"加载索引结果: {idx2[0][:3]}\")\n",
    "print(f\"结果一致: {np.array_equal(idx1, idx2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037311d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量化索引演示\n",
    "print(\"\\n量化索引演示:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# 创建PQ (Product Quantization) 索引\n",
    "dimension = 64\n",
    "m = 8  # PQ的子向量数\n",
    "nbits = 8  # 每个子向量的比特数\n",
    "\n",
    "test_vectors, _ = create_sample_vectors(5000, dimension)\n",
    "\n",
    "# 原始Flat索引\n",
    "index_flat = faiss.IndexFlatL2(dimension)\n",
    "index_flat.add(test_vectors)\n",
    "\n",
    "# PQ索引\n",
    "index_pq = faiss.IndexPQ(dimension, m, nbits)\n",
    "index_pq.train(test_vectors)\n",
    "index_pq.add(test_vectors)\n",
    "\n",
    "print(f\"Flat索引大小: {index_flat.ntotal * dimension * 4 / 1024:.1f} KB\")\n",
    "print(f\"PQ索引大小估计: {index_pq.ntotal * m * nbits / 8 / 1024:.1f} KB\")\n",
    "print(f\"压缩比: {(index_flat.ntotal * dimension * 4) / (index_pq.ntotal * m * nbits / 8):.1f}x\")\n",
    "\n",
    "# 比较搜索质量\n",
    "query = test_vectors[:10]\n",
    "k = 10\n",
    "\n",
    "# Flat搜索\n",
    "dist_flat, idx_flat = index_flat.search(query, k)\n",
    "\n",
    "# PQ搜索\n",
    "dist_pq, idx_pq = index_pq.search(query, k)\n",
    "\n",
    "# 计算召回率\n",
    "recall = calculate_recall(idx_flat, idx_pq, k)\n",
    "print(f\"PQ索引召回率@{k}: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83ac2d",
   "metadata": {},
   "source": [
    "## 8. 最佳实践和优化建议\n",
    "\n",
    "总结FAISS使用的最佳实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53896334",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FAISS最佳实践总结:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "recommendations = {\n",
    "    \"数据规模\": {\n",
    "        \"< 10K向量\": \"使用IndexFlatL2，简单快速\",\n",
    "        \"10K - 100K向量\": \"使用IndexIVFFlat，平衡速度和精度\",\n",
    "        \"100K - 1M向量\": \"使用IndexHNSWFlat或IndexIVFPQ\",\n",
    "        \"> 1M向量\": \"使用IndexIVFPQ或分布式方案\"\n",
    "    },\n",
    "    \"精度要求\": {\n",
    "        \"精确搜索\": \"IndexFlatL2\",\n",
    "        \"高精度近似\": \"IndexHNSWFlat\",\n",
    "        \"平衡精度速度\": \"IndexIVFFlat\",\n",
    "        \"优先速度\": \"IndexIVFPQ\"\n",
    "    },\n",
    "    \"内存限制\": {\n",
    "        \"内存充足\": \"IndexFlatL2或IndexHNSWFlat\",\n",
    "        \"内存有限\": \"IndexIVFPQ或IndexPQ\",\n",
    "        \"极限压缩\": \"IndexPQ with small m\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, items in recommendations.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for scenario, recommendation in items.items():\n",
    "        print(f\"  {scenario}: {recommendation}\")\n",
    "\n",
    "print(\"\\n\\n优化技巧:\")\n",
    "tips = [\n",
    "    \"1. 向量归一化：对于余弦相似度，使用归一化向量\",\n",
    "    \"2. 批量操作：批量添加向量和批量查询以提高效率\",\n",
    "    \"3. GPU加速：对于大规模数据，考虑使用faiss-gpu\",\n",
    "    \"4. 索引调优：根据数据分布调整nlist、nprobe等参数\",\n",
    "    \"5. 内存映射：对于只读索引，使用内存映射减少内存使用\"\n",
    "]\n",
    "\n",
    "for tip in tips:\n",
    "    print(f\"  {tip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理临时文件\n",
    "import os\n",
    "if os.path.exists('../data/faiss_index.bin'):\n",
    "    os.remove('../data/faiss_index.bin')\n",
    "    print(\"已清理临时索引文件\")\n",
    "\n",
    "print(\"\\n演示完成！\")\n",
    "print(\"FAISS是一个强大的向量搜索库，适合各种规模的应用。\")\n",
    "print(\"选择合适的索引类型和参数对于获得最佳性能至关重要。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

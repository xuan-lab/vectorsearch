#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NLTKæ•°æ®ä¸‹è½½å’Œé…ç½®è„šæœ¬
NLTK Data Download and Configuration Script

æœ¬è„šæœ¬ç”¨äºä¸‹è½½å¿…è¦çš„NLTKæ•°æ®åŒ…ï¼Œç¡®ä¿æ–‡æœ¬é¢„å¤„ç†åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚
"""

import os
import sys
import nltk
from pathlib import Path

def download_nltk_data():
    """ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®åŒ…"""
    print("å¼€å§‹ä¸‹è½½NLTKæ•°æ®åŒ…...")
    
    # è®¾ç½®NLTKæ•°æ®ä¸‹è½½ç›®å½•ï¼ˆå¯é€‰ï¼‰
    nltk_data_dir = Path.home() / 'nltk_data'
    print(f"NLTKæ•°æ®å°†å­˜å‚¨åœ¨: {nltk_data_dir}")
    
    # å¿…è¦çš„æ•°æ®åŒ…åˆ—è¡¨
    required_packages = [
        'punkt',           # åˆ†è¯å™¨
        'stopwords',       # åœç”¨è¯
        'wordnet',         # WordNetè¯å…¸
        'averaged_perceptron_tagger',  # è¯æ€§æ ‡æ³¨å™¨
        'punkt_tab',       # Punktåˆ†è¯å™¨è¡¨æ ¼ï¼ˆæ–°ç‰ˆæœ¬éœ€è¦ï¼‰
        'omw-1.4',         # å¼€æ”¾å¤šè¯­è¨€WordNet
    ]
    
    successful_downloads = []
    failed_downloads = []
    
    for package in required_packages:
        try:
            print(f"æ­£åœ¨ä¸‹è½½ {package}...")
            nltk.download(package, quiet=False)
            successful_downloads.append(package)
            print(f"âœ… {package} ä¸‹è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {package} ä¸‹è½½å¤±è´¥: {e}")
            failed_downloads.append(package)
    
    print(f"\nä¸‹è½½æ€»ç»“:")
    print(f"æˆåŠŸä¸‹è½½: {len(successful_downloads)} ä¸ªåŒ…")
    for package in successful_downloads:
        print(f"  âœ… {package}")
    
    if failed_downloads:
        print(f"ä¸‹è½½å¤±è´¥: {len(failed_downloads)} ä¸ªåŒ…")
        for package in failed_downloads:
            print(f"  âŒ {package}")
    else:
        print("ğŸ‰ æ‰€æœ‰å¿…è¦çš„NLTKæ•°æ®åŒ…éƒ½å·²æˆåŠŸä¸‹è½½ï¼")
    
    return len(failed_downloads) == 0

def test_nltk_functionality():
    """æµ‹è¯•NLTKåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("\nå¼€å§‹æµ‹è¯•NLTKåŠŸèƒ½...")
    
    try:
        # æµ‹è¯•åˆ†è¯
        from nltk.tokenize import word_tokenize
        test_text = "This is a test sentence for NLTK functionality."
        tokens = word_tokenize(test_text)
        print(f"âœ… åˆ†è¯æµ‹è¯•æˆåŠŸ: {tokens[:5]}...")
        
        # æµ‹è¯•åœç”¨è¯
        from nltk.corpus import stopwords
        stop_words = set(stopwords.words('english'))
        print(f"âœ… åœç”¨è¯æµ‹è¯•æˆåŠŸ: åŠ è½½äº† {len(stop_words)} ä¸ªè‹±æ–‡åœç”¨è¯")
        
        # æµ‹è¯•è¯å¹²æå–
        from nltk.stem import PorterStemmer
        stemmer = PorterStemmer()
        stem_test = stemmer.stem("running")
        print(f"âœ… è¯å¹²æå–æµ‹è¯•æˆåŠŸ: 'running' -> '{stem_test}'")
        
        print("ğŸ‰ æ‰€æœ‰NLTKåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ NLTKåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def show_nltk_info():
    """æ˜¾ç¤ºNLTKé…ç½®ä¿¡æ¯"""
    print("\nNLTKé…ç½®ä¿¡æ¯:")
    print(f"NLTKç‰ˆæœ¬: {nltk.__version__}")
    print(f"NLTKæ•°æ®è·¯å¾„: {nltk.data.path}")
    
    # æ£€æŸ¥å·²å®‰è£…çš„æ•°æ®åŒ…
    try:
        from nltk.data import find
        installed_packages = []
        test_packages = ['tokenizers/punkt', 'corpora/stopwords', 'corpora/wordnet']
        
        for package in test_packages:
            try:
                find(package)
                installed_packages.append(package.split('/')[-1])
            except LookupError:
                pass
        
        if installed_packages:
            print(f"å·²å®‰è£…çš„æ•°æ®åŒ…: {', '.join(installed_packages)}")
        else:
            print("æœªæ£€æµ‹åˆ°å·²å®‰è£…çš„æ•°æ®åŒ…")
            
    except Exception as e:
        print(f"æ— æ³•æ£€æŸ¥å·²å®‰è£…çš„æ•°æ®åŒ…: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== NLTKæ•°æ®ä¸‹è½½å’Œé…ç½®å·¥å…· ===")
    print("æ­¤å·¥å…·å°†ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®åŒ…ä»¥æ”¯æŒæ–‡æœ¬é¢„å¤„ç†åŠŸèƒ½ã€‚\n")
    
    # æ˜¾ç¤ºå½“å‰NLTKä¿¡æ¯
    show_nltk_info()
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    response = input("\næ˜¯å¦å¼€å§‹ä¸‹è½½NLTKæ•°æ®åŒ…ï¼Ÿ(y/n): ").lower().strip()
    if response not in ['y', 'yes', 'æ˜¯']:
        print("å–æ¶ˆä¸‹è½½ã€‚")
        return
    
    # ä¸‹è½½æ•°æ®åŒ…
    success = download_nltk_data()
    
    if success:
        # æµ‹è¯•åŠŸèƒ½
        test_success = test_nltk_functionality()
        
        if test_success:
            print("\nğŸ‰ NLTKé…ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨å®Œæ•´çš„æ–‡æœ¬é¢„å¤„ç†åŠŸèƒ½äº†ã€‚")
        else:
            print("\nâš ï¸ NLTKæ•°æ®ä¸‹è½½æˆåŠŸï¼Œä½†åŠŸèƒ½æµ‹è¯•å¤±è´¥ã€‚è¯·æ£€æŸ¥é…ç½®ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†NLTKæ•°æ®åŒ…ä¸‹è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•ã€‚")
        print("æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å¤±è´¥çš„æ•°æ®åŒ…ï¼š")
        print("python -c \"import nltk; nltk.download('æ•°æ®åŒ…åç§°')\"")

if __name__ == "__main__":
    main()
